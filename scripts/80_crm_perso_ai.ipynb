{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d0dfa9-3853-4376-bd45-e29856baa625",
   "metadata": {},
   "source": [
    "# Data Assets\n",
    "\n",
    "- Representation of the actual digital footprint within the organisation including accurate recommendations from DCN networks for better performance, user experience and asset management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd424b1-823a-405b-a6ab-de08fd9e1f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import ast\n",
    "import astor\n",
    "import logging\n",
    "import time\n",
    "import inspect\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f036f5b-951a-4659-a02d-fb5e4625e576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading transaction data\n",
    "df = pd.read_csv(\n",
    "    '../data/all_transaction_data.csv'\n",
    ")\n",
    "\n",
    "# Transforming 'quantity' and 'price' columns into 'cost' by scaling between 0 and 1\n",
    "df['cost'] = (df['quantity'] * df['price']).transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# Aggregating interactions by grouping user, product, timestamp, city, and category, and computing sum of 'cost' and mean of 'review_score'\n",
    "interactions_df = df.groupby(\n",
    "    ['user_id',\n",
    "     'product_id',\n",
    "     'timestamp',\n",
    "     'customer_city',\n",
    "     'product_category']\n",
    ").agg(\n",
    "    {'cost': 'sum',\n",
    "     'review_score': 'mean'}\n",
    ").reset_index().rename(columns={'review_score': 'rating'})\n",
    "\n",
    "# Scaling 'rating' between 0 and 1\n",
    "interactions_df['rating'] = (interactions_df['rating'] - interactions_df['rating'].min()) / (interactions_df['rating'].max() - interactions_df['rating'].min())\n",
    "\n",
    "# Handling zero values in 'cost' and 'rating' by replacing them with 0.1\n",
    "interactions_df['cost'] = interactions_df['cost'].replace(0, 0.1)\n",
    "interactions_df['rating'] = interactions_df['rating'].replace(0, 0.1)\n",
    "\n",
    "# Computing 'score' by multiplying 'cost' and 'rating'\n",
    "interactions_df['score'] = interactions_df['cost'] * interactions_df['rating']\n",
    "interactions_df.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "\n",
    "# Creating score percentiles and mapping scores to corresponding labels\n",
    "percentiles = [0, 20, 40, 60, 80, 100]\n",
    "thresholds = [interactions_df['score'].quantile(p / 100) for p in percentiles]\n",
    "labels = [str(i) for i in range(1, len(percentiles))]\n",
    "interactions_df['score'] = pd.cut(interactions_df['score'], bins=thresholds, labels=labels, include_lowest=True).astype(int)\n",
    "\n",
    "# Convert timestamp into string format\n",
    "interactions_df['timestamp'] = pd.to_datetime(interactions_df['timestamp'], unit='s')\n",
    "interactions_df['timestamp'] = interactions_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Combining 'timestamp' and 'user_id' columns and hashing the combined values to create 'order_id'\n",
    "interactions_df['combined_values'] = interactions_df['timestamp'] + '-' + interactions_df['user_id']\n",
    "interactions_df['order_id'] = interactions_df['combined_values'].apply(lambda x: hashlib.sha256(x.encode()).hexdigest()[:32])\n",
    "\n",
    "# Dropping the 'combined_values' column\n",
    "interactions_df = interactions_df.drop(columns=['combined_values', 'cost', 'rating'])\n",
    "\n",
    "# Splitting interactions_df into df, customer_df, and product_df\n",
    "customer_df = interactions_df[['user_id', 'customer_city']].drop_duplicates().reset_index(drop=True)\n",
    "product_df = interactions_df[['item_id', 'product_category']].drop_duplicates().reset_index(drop=True)\n",
    "df = interactions_df.drop(columns=['customer_city', 'product_category'])\n",
    "\n",
    "# Resetting index for customer_df, product_df, and df\n",
    "customer_df.reset_index(drop=True, inplace=True)\n",
    "product_df.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Saving dataframes to CSV files\n",
    "df.to_csv('../data/df_data.csv', index=False)\n",
    "customer_df.to_csv('../data/customer_df_data.csv', index=False)\n",
    "product_df.to_csv('../data/product_df_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37551758-fd73-4e68-a224-542da09e21b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare Globals\n",
    "orig_df = pd.read_csv('../data/df_data.csv')\n",
    "orig_customer_df = pd.read_csv('../data/customer_df_data.csv')\n",
    "orig_product_df = pd.read_csv('../data/product_df_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e439c2b-e820-4038-aebb-3bc38c75ca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>score</th>\n",
       "      <th>order_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>UNKNOWN SKU 4</td>\n",
       "      <td>2017-02-16 15:56:11</td>\n",
       "      <td>2</td>\n",
       "      <td>a8b293fba4541a7bbee981c3fab93a87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>air_conditioning SKU 1</td>\n",
       "      <td>2018-02-25 21:50:31</td>\n",
       "      <td>2</td>\n",
       "      <td>3f1445bfa33a3a270e0a1c6170525383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>auto SKU 1217</td>\n",
       "      <td>2017-05-19 13:27:20</td>\n",
       "      <td>5</td>\n",
       "      <td>afbe3b6ad076ea9bc293c441d28d77b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>auto SKU 1446</td>\n",
       "      <td>2018-01-06 13:57:08</td>\n",
       "      <td>3</td>\n",
       "      <td>0c4c43df1bd04be00299bc0d8763d27b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>auto SKU 1524</td>\n",
       "      <td>2018-06-06 11:47:08</td>\n",
       "      <td>2</td>\n",
       "      <td>c8c018c57619b3d48800ee01d16db3bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                 item_id  \\\n",
       "0  0000366f3b9a7992bf8c76cfdf3221e2           UNKNOWN SKU 4   \n",
       "1  0000366f3b9a7992bf8c76cfdf3221e2  air_conditioning SKU 1   \n",
       "2  0000366f3b9a7992bf8c76cfdf3221e2           auto SKU 1217   \n",
       "3  0000366f3b9a7992bf8c76cfdf3221e2           auto SKU 1446   \n",
       "4  0000366f3b9a7992bf8c76cfdf3221e2           auto SKU 1524   \n",
       "\n",
       "             timestamp  score                          order_id  \n",
       "0  2017-02-16 15:56:11      2  a8b293fba4541a7bbee981c3fab93a87  \n",
       "1  2018-02-25 21:50:31      2  3f1445bfa33a3a270e0a1c6170525383  \n",
       "2  2017-05-19 13:27:20      5  afbe3b6ad076ea9bc293c441d28d77b1  \n",
       "3  2018-01-06 13:57:08      3  0c4c43df1bd04be00299bc0d8763d27b  \n",
       "4  2018-06-06 11:47:08      2  c8c018c57619b3d48800ee01d16db3bc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21783856-e562-47a8-9cab-4b08026a829f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>customer_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>cajamar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000b849f77a49e4a4ce2b2a4ca5be3f</td>\n",
       "      <td>osasco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000f46a3911fa3c0805444483337064</td>\n",
       "      <td>sao jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000f6ccb0745a6a4b88665a16c9f078</td>\n",
       "      <td>belem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004aac84e0df4da2b147fca70cf8255</td>\n",
       "      <td>sorocaba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id customer_city\n",
       "0  0000366f3b9a7992bf8c76cfdf3221e2       cajamar\n",
       "1  0000b849f77a49e4a4ce2b2a4ca5be3f        osasco\n",
       "2  0000f46a3911fa3c0805444483337064      sao jose\n",
       "3  0000f6ccb0745a6a4b88665a16c9f078         belem\n",
       "4  0004aac84e0df4da2b147fca70cf8255      sorocaba"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18e2651-43ae-460a-ac7c-601a4f5ee9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNKNOWN SKU 4</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_conditioning SKU 1</td>\n",
       "      <td>air_conditioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto SKU 1217</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto SKU 1446</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto SKU 1524</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id  product_category\n",
       "0           UNKNOWN SKU 4           UNKNOWN\n",
       "1  air_conditioning SKU 1  air_conditioning\n",
       "2           auto SKU 1217              auto\n",
       "3           auto SKU 1446              auto\n",
       "4           auto SKU 1524              auto"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15756bf5-c2f6-419d-b5c7-2b67e0c9b9f1",
   "metadata": {},
   "source": [
    "# LLM Pre-Requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad6150b-df49-4248-9e52-8df0fc2aa61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def data_copy(orig_df, orig_customer_df, orig_product_df):\n",
    "    \"\"\"\n",
    "    This function creates deep copies of the original data frames to prevent modification of the original data.\n",
    "\n",
    "    Parameters:\n",
    "    - `orig_df`: Original DataFrame containing transaction data.\n",
    "    - `orig_customer_df`: Original DataFrame containing customer data.\n",
    "    - `orig_product_df`: Original DataFrame containing product data.\n",
    "\n",
    "    Returns:\n",
    "    - `df`: Deep copy of the original transaction DataFrame.\n",
    "    - `customer_df`: Deep copy of the original customer DataFrame.\n",
    "    - `product_df`: Deep copy of the original product DataFrame.\n",
    "    \"\"\"\n",
    "    df = orig_df.copy(deep=True)\n",
    "    customer_df = orig_customer_df.copy(deep=True)\n",
    "    product_df = orig_product_df.copy(deep=True)\n",
    "    return df, customer_df, product_df\n",
    "\n",
    "def create_question_context_dict(message):\n",
    "    \"\"\"\n",
    "    Create a dictionary with question as key and context as value\n",
    "\n",
    "    Args:\n",
    "        message (list): A list containing dictionaries for question, context, and answer.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of question as key and context as value\n",
    "    \"\"\"\n",
    "    # Extracting question, context, and answer from the message\n",
    "    question = message[1]['content']\n",
    "    context = message[0]['content']\n",
    "    answer = message[2]['content']\n",
    "\n",
    "    return {question: context}\n",
    "\n",
    "def parse_function_definition(definition_string):\n",
    "    \"\"\"\n",
    "    This function parses a given function definition string and extracts important information such as function name, arguments, and body statements. It then constructs a complete function definition string by adding necessary imports and the original function definition.\n",
    "\n",
    "    Parameters:\n",
    "    - `definition_string`: The string representing the function definition.\n",
    "\n",
    "    Returns:\n",
    "    - `function_name`: Name of the parsed function.\n",
    "    - `arguments`: List of arguments of the parsed function.\n",
    "    - `body`: Body statements of the parsed function.\n",
    "    - `function_definition`: Complete function definition string including necessary imports and the original function definition.\n",
    "    \"\"\"\n",
    "    # Parse the definition string\n",
    "    parsed = ast.parse(definition_string)\n",
    "    \n",
    "    # Initialize variables\n",
    "    function_name = None\n",
    "    arguments = []\n",
    "    body = []\n",
    "    \n",
    "    # Iterate over parsed body\n",
    "    for node in parsed.body:\n",
    "        # Check if node is a function definition\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            # Get function name\n",
    "            function_name = node.name\n",
    "            # Get function arguments\n",
    "            arguments = [arg.arg for arg in node.args.args]\n",
    "            \n",
    "            # Iterate over function body statements\n",
    "            for stmt in node.body:\n",
    "                # Convert AST node to source code and append to body list\n",
    "                body.append(astor.to_source(stmt).strip())\n",
    "    \n",
    "    # Construct complete function definition string\n",
    "    function_definition = (\n",
    "        \"\\n\"\n",
    "        # Import necessary modules\n",
    "        f\"import pandas as pd\\n\"\n",
    "        f\"import numpy as np\\n\"\n",
    "        f\"from numpy.linalg import LinAlgError\\n\"\n",
    "        f\"from datetime import datetime, timedelta\\n\"\n",
    "        f\"from collections import defaultdict, Counter\\n\"\n",
    "        f\"from itertools import combinations\\n\"\n",
    "        f\"from scipy.sparse import csr_matrix\\n\"\n",
    "        f\"from scipy.stats import zscore\\n\"\n",
    "        f\"from sklearn.preprocessing import StandardScaler, LabelEncoder\\n\"\n",
    "        f\"from sklearn.cluster import KMeans\\n\"\n",
    "        f\"from sklearn.model_selection import train_test_split\\n\"\n",
    "        f\"from sklearn.linear_model import LogisticRegression, LinearRegression\\n\"\n",
    "        f\"from sklearn.metrics.pairwise import cosine_similarity\\n\"\n",
    "        f\"from sklearn.feature_extraction.text import TfidfVectorizer\\n\"\n",
    "        f\"from sklearn.decomposition import TruncatedSVD\\n\"\n",
    "        f\"from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\\n\"\n",
    "        f\"from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\\n\"\n",
    "        f\"from mlxtend.frequent_patterns import apriori\\n\"\n",
    "        f\"from mlxtend.frequent_patterns import association_rules\\n\"\n",
    "        f\"from surprise import Reader, Dataset\\n\"\n",
    "        f\"from surprise.prediction_algorithms import SVD\\n\"\n",
    "        f\"from matplotlib import pyplot as plt\\n\"\n",
    "        f\"from statsmodels.tsa.statespace.sarimax import SARIMAX\\n\"\n",
    "        f\"from statsmodels.tools.sm_exceptions import ConvergenceWarning\\n\"\n",
    "        f\"from statsmodels.tsa.seasonal import seasonal_decompose\\n\"\n",
    "        f\"import warnings\\n\"\n",
    "        f\"import seaborn as sns\\n\"\n",
    "        # Append original function definition\n",
    "        f\"{definition_string}\"\n",
    "    )\n",
    "    return function_name, arguments, '\\n'.join(body), function_definition\n",
    "\n",
    "def encode_and_move_embeddings_to_gpu(query, embedder):\n",
    "    \"\"\"\n",
    "    Encodes a query and moves the embeddings to GPU.\n",
    "\n",
    "    Args:\n",
    "        query (str): The input query to encode.\n",
    "        embedder: The embedding model to use for encoding.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The encoded query embeddings on GPU.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True).to(\"cuda\")\n",
    "    logging.info(f\"\\nTime for encoding and moving embeddings to GPU: {time.time() - start_time} seconds\")\n",
    "    return query_embedding\n",
    "\n",
    "def normalize_embeddings(embeddings, util):\n",
    "    \"\"\"\n",
    "    Normalizes embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings (torch.Tensor): The embeddings to normalize.\n",
    "        util: The utility object for normalization.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The normalized embeddings.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    normalized_embeddings = util.normalize_embeddings(embeddings)\n",
    "    logging.info(f\"\\nTime for normalizing embeddings: {time.time() - start_time} seconds\")\n",
    "    return normalized_embeddings\n",
    "\n",
    "def semantic_search(query_embedding, train_corpus_embeddings, util):\n",
    "    \"\"\"\n",
    "    Performs semantic search using query embedding and train corpus embeddings.\n",
    "\n",
    "    Args:\n",
    "        query_embedding (torch.Tensor): The embedding of the query.\n",
    "        train_corpus_embeddings (torch.Tensor): The embeddings of the training corpus.\n",
    "        util: The utility object for semantic search.\n",
    "\n",
    "    Returns:\n",
    "        list: List of hits from the semantic search.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    hits = util.semantic_search(query_embedding, train_corpus_embeddings, score_function=util.dot_score, top_k=1)\n",
    "    logging.info(f\"\\nTime for semantic search: {time.time() - start_time} seconds\")\n",
    "    return hits\n",
    "\n",
    "def retrieve_context(hits, train_question_context_dict, train_questions_corpus):\n",
    "    \"\"\"\n",
    "    Retrieves context based on hits from semantic search.\n",
    "\n",
    "    Args:\n",
    "        hits (list): List of hits from semantic search.\n",
    "        train_question_context_dict (dict): Dictionary mapping questions to their contexts.\n",
    "        train_questions_corpus (list): List of questions in the training corpus.\n",
    "\n",
    "    Returns:\n",
    "        str: Retrieved context.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    retrieved_context = train_question_context_dict[train_questions_corpus[hits[0][0]['corpus_id']]]\n",
    "    logging.info(f\"\\nTime for retrieving context: {time.time() - start_time} seconds\")\n",
    "    return retrieved_context\n",
    "\n",
    "def create_prompt(test_query, retrieved_context):\n",
    "    \"\"\"\n",
    "    Creates a prompt for generating the answer.\n",
    "\n",
    "    Args:\n",
    "        test_query (str): The test query.\n",
    "        retrieved_context (str): The retrieved context.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated prompt.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    ### Question: {test_query}\n",
    "\n",
    "    ### Context: {retrieved_context}\n",
    "    USE ONLY DEFINED DATAFRAMES AND INCLUDE THESE AS ARGUMENTS.\n",
    "    NO NEED TO CONSIDER ANY EXTERNAL DATA SOURCES, VARIABLES OR DATAFRAMES APART FROM THE ONES ALREADY AVAILABLE IN THE GLOBALS.\n",
    "    THE GENERATED ANSWER SHOULD BE A SINGLE PYTHON FUNCTION WITH A `def` AND `return` ONLY.\n",
    "    THE GENERATED CODE SHOULD BE COMPLETE IN ITSELF, SYNTACTICALLY CORRECT AND BE PARSED SUCCESSFULLY.\n",
    "    NO NEED TO CALL THE FUNCTION OR PRINT THE FUNCTION CALL. NO NEED TO INCLUDE MAIN CALL. JUST PROVIDING THE PYTHON FUNCTION IS SUFFICIENT.\n",
    "    \n",
    "    ### Answer:\n",
    "    \"\"\".strip()\n",
    "    return prompt\n",
    "\n",
    "def tokenize_prompt(prompt, test_tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes the prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to tokenize.\n",
    "        test_tokenizer: The tokenizer to use.\n",
    "\n",
    "    Returns:\n",
    "        dict: Model input with tokenized prompt.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model_input = test_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    logging.info(f\"\\nTime for tokenizing prompt: {time.time() - start_time} seconds\")\n",
    "    return model_input\n",
    "\n",
    "def generate_text(model_input, ft_model, eval_tokenizer):\n",
    "    \"\"\"\n",
    "    Generates text based on model input.\n",
    "\n",
    "    Args:\n",
    "        model_input (dict): Model input with tokenized prompt.\n",
    "        ft_model: The fine-tuned model for text generation.\n",
    "        eval_tokenizer: The tokenizer for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Generated tokens.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = ft_model.generate(\n",
    "            **model_input,\n",
    "            max_new_tokens=1024,\n",
    "            repetition_penalty=1.15,\n",
    "            pad_token_id=eval_tokenizer.eos_token_id\n",
    "        )[0]\n",
    "    logging.info(f\"\\nTime for generating text: {time.time() - start_time} seconds\")\n",
    "    return generated_tokens\n",
    "\n",
    "def decode_generated_text(generated_tokens, eval_tokenizer):\n",
    "    \"\"\"\n",
    "    Decodes generated text tokens.\n",
    "\n",
    "    Args:\n",
    "        generated_tokens (torch.Tensor): Generated tokens.\n",
    "        eval_tokenizer: The tokenizer for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        str: Decoded generated text.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    generated_text = eval_tokenizer.decode(\n",
    "        generated_tokens,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    logging.info(f\"\\nTime for decoding generated text: {time.time() - start_time} seconds\")\n",
    "    return generated_text\n",
    "\n",
    "def process_answer(generated_text):\n",
    "    \"\"\"\n",
    "    Processes the generated text to extract the answer.\n",
    "\n",
    "    Args:\n",
    "        generated_text (str): The generated text.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed answer.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    start_marker = \"### Answer:\"\n",
    "    start_index = generated_text.find(start_marker) + len(start_marker)\n",
    "\n",
    "    if start_index == -1:\n",
    "        return \"No answer found.\"\n",
    "\n",
    "    answer = generated_text[start_index:].strip()\n",
    "\n",
    "    end_marker = None\n",
    "    if \"### Explanation:\" in answer:\n",
    "        end_marker = \"### Explanation:\"\n",
    "    elif \"### \" in answer:\n",
    "        end_marker = \"### \"\n",
    "\n",
    "    if end_marker:\n",
    "        end_index = answer.find(end_marker)\n",
    "        if end_index != -1:\n",
    "            answer = answer[:end_index].strip()\n",
    "\n",
    "    end_of_function_index = answer.find(\"\\r\\n\")\n",
    "    if end_of_function_index != -1:\n",
    "        answer = answer[:end_of_function_index].strip()\n",
    "\n",
    "    end_of_function_index = answer.find(\"if __name__ ==\")\n",
    "    if end_of_function_index != -1:\n",
    "        answer = answer[:end_of_function_index].strip()\n",
    "\n",
    "    answer = answer.replace(\"\\\\\\\\\", \"\\\\\").strip().replace(\"\\\\n\", \"\\n\").rstrip('\\\\').replace(\"\\\\'\", \"'\").strip()\n",
    "    logging.info(f\"\\nTime for processing answer string: {time.time() - start_time} seconds\")\n",
    "    return answer\n",
    "\n",
    "def print_assistant_message(function_definition):\n",
    "    \"\"\"\n",
    "    Prints a message from the assistant.\n",
    "\n",
    "    Args:\n",
    "        function_definition (str): The definition of the function.\n",
    "    \"\"\"\n",
    "    print(f\"\"\"\n",
    "    Assistant:\n",
    "    {function_definition}\n",
    "    \"\"\")\n",
    "\n",
    "def execute_function(parsed_function, globals_, arguments):\n",
    "    \"\"\"\n",
    "    Executes a parsed function.\n",
    "\n",
    "    Args:\n",
    "        parsed_function (str): The name of the function to execute.\n",
    "        globals_ (dict): Global namespace dictionary.\n",
    "        arguments (tuple): Arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        any: Result of the executed function.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    _parsed_function = globals_[parsed_function]\n",
    "    _signature = inspect.signature(_parsed_function)\n",
    "    _parameters_with_defaults = [(param.name, param.default) for param in _signature.parameters.values() if param.default != inspect.Parameter.empty]\n",
    "    _default_values = dict(_parameters_with_defaults)\n",
    "    _args = tuple(_default_values[arg] if arg in _default_values else globals()[arg] for arg in arguments)\n",
    "    result = _parsed_function(*_args)\n",
    "    logging.info(f\"\\nTime for executing function: {time.time() - start_time} seconds\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96768c51-c79c-4353-b5e0-ce98fb4c8fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a283602f2d4f6ea6d9b676aa1526a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab63b9dc57864cf0a5a8d4f5948d484b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=64, out_features=32000, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training dataset\n",
    "train_dataset = load_dataset('json', data_files='../data/train_CRM_data.json', split='train')\n",
    "\n",
    "train_question_context_dict = {}\n",
    "\n",
    "# Iterate through each example in the training dataset\n",
    "for sample in train_dataset:\n",
    "    \n",
    "    # Extract question and context using create_question_context_dict function\n",
    "    qc_pair = create_question_context_dict(sample['messages'])\n",
    "    \n",
    "    # Merge the extracted pairs into the train_question_context_dict\n",
    "    train_question_context_dict.update(qc_pair)\n",
    "\n",
    "# Define Mistral's pretrained model ID\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# Define BitsAndBytesConfig for Mistral's model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                    # Load the model in 4-bit precision\n",
    "    bnb_4bit_use_double_quant=True,       # Use double quantization for 4-bit quantization\n",
    "    bnb_4bit_quant_type=\"nf4\",            # Use nf4 quantization for 4-bit quantization\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 # Use bfloat16 for computation with 4-bit quantization\n",
    ")\n",
    "\n",
    "# Load Mistral's pretrained model for causal language modeling\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id, \n",
    "    quantization_config=bnb_config, # Apply the defined quantization configuration\n",
    "    device_map=\"auto\"               # Automatically select the device for model inference\n",
    ")\n",
    "\n",
    "# Load Mistral's tokenizer\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id, \n",
    "    add_bos_token=True,     # Add beginning-of-sequence token\n",
    "    trust_remote_code=True  # Trust remote code for tokenization\n",
    ")\n",
    "\n",
    "# Load the weights from the checkpoint directory\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"../models/01-finetune-mistral/checkpoint-150\")\n",
    "\n",
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\") # best identified pre-trained model for embeddings w.r.t. semantic search\n",
    "\n",
    "# Extracting all questions from train_question_context_dict\n",
    "train_questions_corpus = list(train_question_context_dict.keys())\n",
    "\n",
    "# Encode the training questions into embeddings and move them to GPU if available\n",
    "train_corpus_embeddings = embedder.encode(\n",
    "    train_questions_corpus, \n",
    "    convert_to_tensor=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Normalize the embeddings\n",
    "train_corpus_embeddings = util.normalize_embeddings(train_corpus_embeddings)\n",
    "\n",
    "# Init a tokenizer that doesn't add padding or eos token\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "# Set the fine-tuned model to evaluation mode\n",
    "ft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a37482-ff4f-4e29-9d4f-8e5226443994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_response(user_query, mode=None):\n",
    "    \"\"\"\n",
    "    Generate a response based on the user's query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query.\n",
    "\n",
    "    Returns:\n",
    "    result: The result of the executed function.\n",
    "    \"\"\"\n",
    "    # Print user query for logging\n",
    "    print(f\"User query: {user_query}\")\n",
    "    \n",
    "    result = None\n",
    "\n",
    "    # Start time for measuring query execution time\n",
    "    query_start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Encode the test query into embeddings and move them to GPU if available\n",
    "        query_embedding = encode_and_move_embeddings_to_gpu([user_query], embedder)\n",
    "\n",
    "        # Normalize the embeddings\n",
    "        query_embedding = normalize_embeddings(query_embedding, util)\n",
    "\n",
    "        # Find the most similar question in the training set for the test query\n",
    "        hits = semantic_search(query_embedding, train_corpus_embeddings, util)\n",
    "\n",
    "        # Retrieve the context corresponding to the most similar question\n",
    "        retrieved_context = retrieve_context(hits, train_question_context_dict, train_questions_corpus)\n",
    "\n",
    "        # Create a prompt with the test query and the retrieved context\n",
    "        prompt = create_prompt(user_query, retrieved_context)\n",
    "\n",
    "        # Tokenize the test prompt and prepare model input for inference\n",
    "        model_input = tokenize_prompt(prompt, test_tokenizer)\n",
    "\n",
    "        # Generate text based on the model input\n",
    "        generated_tokens = generate_text(model_input, ft_model, eval_tokenizer)\n",
    "\n",
    "        # Decode the generated tokens into text, skipping special tokens\n",
    "        generated_text = decode_generated_text(generated_tokens, eval_tokenizer)\n",
    "\n",
    "        # Process the generated text to extract the answer\n",
    "        answer = process_answer(generated_text)\n",
    "\n",
    "        # Parse the function definition and retrieve function name, arguments, and complete function definition\n",
    "        function_name, arguments, body, function_definition = parse_function_definition(answer)\n",
    "        \n",
    "        if mode == \"FULL\":\n",
    "            print(f\"\\nASSISTANT:\\n\\n{function_definition}\")\n",
    "\n",
    "        # Execute the parsed function definition\n",
    "        globals_ = {'df': df, 'customer_df': customer_df, 'product_df': product_df}\n",
    "        exec(function_definition, globals_)\n",
    "        result = execute_function(function_name, globals_, arguments)\n",
    "\n",
    "    except Exception as err:\n",
    "        # Log error and retry logic\n",
    "        logging.error(f\"Error occurred: {err}\")\n",
    "        print(\"The model ran into an error. Retrying...\")\n",
    "\n",
    "        # Retry logic\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                # Generate text for error handling\n",
    "                error_prompt = f\"### Question: {user_query}. Do not use {err} in your response.\\n\\n### Context: {retrieved_context}\\n\\n### Answer:\"\n",
    "                model_input = tokenize_prompt(error_prompt, test_tokenizer)\n",
    "                generated_tokens = generate_text(model_input, ft_model, eval_tokenizer)\n",
    "                generated_text = decode_generated_text(generated_tokens, eval_tokenizer)\n",
    "                answer = process_answer(generated_text)\n",
    "\n",
    "                # Parse, execute, and return result\n",
    "                function_name, arguments, body, function_definition = parse_function_definition(answer)\n",
    "                if mode == \"FULL\":\n",
    "                    print(f\"\\nASSISTANT:\\n\\n{function_definition}\")\n",
    "                globals_ = {'df': df, 'customer_df': customer_df, 'product_df': product_df}\n",
    "                exec(function_definition, globals_)\n",
    "                result = execute_function(function_name, globals_, arguments)\n",
    "                break\n",
    "            except Exception as retry_err:\n",
    "                # Log retry error\n",
    "                logging.error(f\"Retry error occurred: {retry_err}\")\n",
    "                print(\"The model ran into an error. Retrying...\")\n",
    "\n",
    "    # Log total execution time\n",
    "    logging.info(f\"Total execution time: {time.time() - query_start_time} seconds\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a6be5-a92c-446c-9eb2-ef35824d4709",
   "metadata": {},
   "source": [
    "# Actual Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455e881a-5472-45de-9343-a4840f012203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Which is the starting date of the last week?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9c0b0e8e3346108f134b60fa0196fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for encoding and moving embeddings to GPU: 0.020400524139404297 seconds\n",
      "INFO:root:\n",
      "Time for normalizing embeddings: 0.0002434253692626953 seconds\n",
      "INFO:root:\n",
      "Time for semantic search: 0.011563539505004883 seconds\n",
      "INFO:root:\n",
      "Time for retrieving context: 4.5299530029296875e-06 seconds\n",
      "INFO:root:\n",
      "Time for tokenizing prompt: 0.0017457008361816406 seconds\n",
      "2024-05-06 22:44:16.273262: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 22:44:16.317068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 22:44:17.147009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:root:\n",
      "Time for generating text: 17.38933753967285 seconds\n",
      "INFO:root:\n",
      "Time for decoding generated text: 0.0013506412506103516 seconds\n",
      "INFO:root:\n",
      "Time for processing answer string: 1.7881393432617188e-05 seconds\n",
      "INFO:root:\n",
      "Time for executing function: 0.00022268295288085938 seconds\n",
      "INFO:root:Total execution time: 17.812812089920044 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-05-01 22:44:33.512301')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"Which is the starting date of the last week?\"\n",
    "\n",
    "# Copy original data frames\n",
    "df, customer_df, product_df = data_copy(orig_df, orig_customer_df, orig_product_df)\n",
    "\n",
    "get_response(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33dff6c0-8e8b-4613-8b91-c9804fce83e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: What is the most recommended product in sao jose?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b116257cdf34c009a2037300a9c3d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for encoding and moving embeddings to GPU: 0.017342329025268555 seconds\n",
      "INFO:root:\n",
      "Time for normalizing embeddings: 0.00025773048400878906 seconds\n",
      "INFO:root:\n",
      "Time for semantic search: 0.00028634071350097656 seconds\n",
      "INFO:root:\n",
      "Time for retrieving context: 3.337860107421875e-06 seconds\n",
      "INFO:root:\n",
      "Time for tokenizing prompt: 0.0019958019256591797 seconds\n",
      "INFO:root:\n",
      "Time for generating text: 22.757999420166016 seconds\n",
      "INFO:root:\n",
      "Time for decoding generated text: 0.000993967056274414 seconds\n",
      "INFO:root:\n",
      "Time for processing answer string: 1.52587890625e-05 seconds\n",
      "INFO:root:\n",
      "Time for executing function: 9.283386468887329 seconds\n",
      "INFO:root:Total execution time: 32.06792902946472 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'watches_gifts'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"What is the most recommended product in sao jose?\"\n",
    "\n",
    "# Copy original data frames\n",
    "df, customer_df, product_df = data_copy(orig_df, orig_customer_df, orig_product_df)\n",
    "\n",
    "get_response(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67427c31-e95e-48ae-8c4a-86468b4e1d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Which customer has made the highest number of transactions?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3a96e4a38e4c4ab939fbf9491c6258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for encoding and moving embeddings to GPU: 0.2826223373413086 seconds\n",
      "INFO:root:\n",
      "Time for normalizing embeddings: 0.00025963783264160156 seconds\n",
      "INFO:root:\n",
      "Time for semantic search: 0.00029468536376953125 seconds\n",
      "INFO:root:\n",
      "Time for retrieving context: 5.0067901611328125e-06 seconds\n",
      "INFO:root:\n",
      "Time for tokenizing prompt: 0.0027217864990234375 seconds\n",
      "INFO:root:\n",
      "Time for generating text: 11.029001951217651 seconds\n",
      "INFO:root:\n",
      "Time for decoding generated text: 0.0009272098541259766 seconds\n",
      "INFO:root:\n",
      "Time for processing answer string: 1.3113021850585938e-05 seconds\n",
      "INFO:root:\n",
      "Time for executing function: 4.005300283432007 seconds\n",
      "INFO:root:Total execution time: 15.326114416122437 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000366f3b9a7992bf8c76cfdf3221e2</td>\n",
       "      <td>3.185841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id     score\n",
       "0  0000366f3b9a7992bf8c76cfdf3221e2  3.185841"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"Which customer has made the highest number of transactions?\"\n",
    "\n",
    "# Copy original data frames\n",
    "df, customer_df, product_df = data_copy(orig_df, orig_customer_df, orig_product_df)\n",
    "\n",
    "get_response(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6aecde3-650a-4609-a482-ed324c31cc58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Calculate the total number of orders by year and plot the trend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f650878755485e8f23ab77149b63b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for encoding and moving embeddings to GPU: 0.01801776885986328 seconds\n",
      "INFO:root:\n",
      "Time for normalizing embeddings: 0.0002346038818359375 seconds\n",
      "INFO:root:\n",
      "Time for semantic search: 0.0002810955047607422 seconds\n",
      "INFO:root:\n",
      "Time for retrieving context: 6.4373016357421875e-06 seconds\n",
      "INFO:root:\n",
      "Time for tokenizing prompt: 0.001226186752319336 seconds\n",
      "INFO:root:\n",
      "Time for generating text: 6.55596923828125 seconds\n",
      "INFO:root:\n",
      "Time for decoding generated text: 0.0006616115570068359 seconds\n",
      "INFO:root:\n",
      "Time for processing answer string: 1.0251998901367188e-05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT:\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from numpy.linalg import LinAlgError\n",
      "from datetime import datetime, timedelta\n",
      "from collections import defaultdict, Counter\n",
      "from itertools import combinations\n",
      "from scipy.sparse import csr_matrix\n",
      "from scipy.stats import zscore\n",
      "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
      "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
      "from mlxtend.frequent_patterns import apriori\n",
      "from mlxtend.frequent_patterns import association_rules\n",
      "from surprise import Reader, Dataset\n",
      "from surprise.prediction_algorithms import SVD\n",
      "from matplotlib import pyplot as plt\n",
      "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
      "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
      "from statsmodels.tsa.seasonal import seasonal_decompose\n",
      "import warnings\n",
      "import seaborn as sns\n",
      "def calculate_total_orders_by_year(df):\n",
      "    df['year'] = pd.to_datetime(df['timestamp']).dt.year\n",
      "    return df.groupby('year').size().reset_index(name='total_orders')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for executing function: 2.4113712310791016 seconds\n",
      "INFO:root:Total execution time: 8.992732763290405 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>32469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>4520566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>5446926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  total_orders\n",
       "0  2016         32469\n",
       "1  2017       4520566\n",
       "2  2018       5446926"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"Calculate the total number of orders by year and plot the trend.\"\n",
    "\n",
    "# Copy original data frames\n",
    "df, customer_df, product_df = data_copy(orig_df, orig_customer_df, orig_product_df)\n",
    "\n",
    "get_response(user_query, mode=\"FULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bbaed88-2b06-4b6f-89aa-4fc20f107fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: Plot the total number of orders by year.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bbb5a1cd6c4ca0a2198ecde371707e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for encoding and moving embeddings to GPU: 0.01862478256225586 seconds\n",
      "INFO:root:\n",
      "Time for normalizing embeddings: 0.00028014183044433594 seconds\n",
      "INFO:root:\n",
      "Time for semantic search: 0.0003330707550048828 seconds\n",
      "INFO:root:\n",
      "Time for retrieving context: 4.76837158203125e-06 seconds\n",
      "INFO:root:\n",
      "Time for tokenizing prompt: 0.0013742446899414062 seconds\n",
      "INFO:root:\n",
      "Time for generating text: 18.955355405807495 seconds\n",
      "INFO:root:\n",
      "Time for decoding generated text: 0.0012180805206298828 seconds\n",
      "INFO:root:\n",
      "Time for processing answer string: 1.1444091796875e-05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSISTANT:\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from numpy.linalg import LinAlgError\n",
      "from datetime import datetime, timedelta\n",
      "from collections import defaultdict, Counter\n",
      "from itertools import combinations\n",
      "from scipy.sparse import csr_matrix\n",
      "from scipy.stats import zscore\n",
      "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
      "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
      "from mlxtend.frequent_patterns import apriori\n",
      "from mlxtend.frequent_patterns import association_rules\n",
      "from surprise import Reader, Dataset\n",
      "from surprise.prediction_algorithms import SVD\n",
      "from matplotlib import pyplot as plt\n",
      "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
      "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
      "from statsmodels.tsa.seasonal import seasonal_decompose\n",
      "import warnings\n",
      "import seaborn as sns\n",
      "def plot_total_orders_by_year(df):\n",
      "    \"\"\"Plot the total number of orders per year.\"\"\"\n",
      "    df['year'] = pd.to_datetime(df['timestamp']).dt.year\n",
      "    total_orders = df.groupby('year').size().reset_index(name='total_orders')\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.plot(total_orders['year'], total_orders['total_orders'], marker='o', linestyle='-', color='blue')\n",
      "    plt.xlabel('Year')\n",
      "    plt.ylabel('Total Orders')\n",
      "    plt.title('Total Number of Orders Per Year')\n",
      "    plt.grid()\n",
      "    plt.show()\n",
      "    return None\n",
      "\n",
      "\n",
      "###\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABry0lEQVR4nO3deZyN5f/H8feZxYwZZiwzdiFblkRjicoSYytLRUVKIvpGKq1arFlaFEkbRURkj+y7ikKUItn3fRsGY5br98f9m8NxBjPMmfvMnNfz8fAw5z7XnPM5HzfOe67rXLfDGGMEAAAAAD7Cz+4CAAAAACAjEYIAAAAA+BRCEAAAAACfQggCAAAA4FMIQQAAAAB8CiEIAAAAgE8hBAEAAADwKYQgAAAAAD6FEAQAAADApxCCAOAmLVu2TA6HQ8uWLbO7lBuW/BqmTJlidympcvjwYbVq1Up58+aVw+HQ0KFDba2nT58+cjgcttYAAEg9QhCATMnhcKTqV2qCycCBAzVjxgyP1zxmzBg5HA4FBwdr//79bvfXrVtXFStW9HgdWcFLL72k+fPnq2fPnho3bpwaN258zfGxsbHq37+/KlWqpJCQEIWHh+vee+/V2LFjZYzJoKozTt26dV3+HuTJk0fVqlXTN998o6SkJI8976pVq+Tn56eePXumeP97770nh8Ohn376yWM1AEBqBNhdAADciHHjxrncHjt2rBYuXOh2vFy5ctd9rIEDB6pVq1Zq2bJlepZ4VXFxcRo8eLCGDx+eIc+XFS1ZskQtWrTQK6+8ct2xhw8fVv369bV582Y99thj6tatmy5cuKCpU6eqffv2mjNnjsaPHy9/f/8MqDzjFClSRIMGDZIkHT16VGPHjlXHjh3133//afDgwR55zpo1a6pLly4aMmSI2rVrpwoVKjjv2717t/r166fWrVvr/vvv98jzA0BqEYIAZErt2rVzub169WotXLjQ7bg3qly5skaOHKmePXuqUKFCdpeToWJjYxUaGnrTj3PkyBHlypUrVWPbt2+vzZs3a/r06WrevLnzePfu3fXqq6/qww8/VJUqVfT6669f9TESEhKUlJSkbNmy3WzpqXLu3DmFhITc1GOEh4e7/H3o0qWLypYtq08//VT9+/dXYGDgDT/2tfoxePBgzZw5U126dNHKlSudywSff/55BQYGatiwYTf8vGmRHj0EkHWxHA5AlhUbG6uXX35ZRYsWVVBQkMqWLasPP/zQZfmTw+FQbGysvv32W+fSoaeeekqS9ZPr5557TmXLllX27NmVN29etW7dWrt27bqput58800lJiZe96fxu3btksPh0JgxY9zuczgc6tOnj/N28mdS/vvvP7Vr107h4eGKjIzUO++8I2OM9u7dqxYtWigsLEwFChTQkCFDUnzOxMREvfnmmypQoIBCQ0PVvHlz7d27123cb7/9psaNGys8PFwhISGqU6eOfvnlF5cxyTVt2rRJbdu2Ve7cuXXPPfdc8zXv2LFDrVu3Vp48eRQSEqK77rrLZelU8pJCY4xGjBjh/DO7mtWrV2v+/Pl66qmnXAJQskGDBql06dJ67733dP78eUmX+v7hhx9q6NChKlmypIKCgrRp0yZJ0s8//6xq1aopODhYJUuW1JdffnnV5//uu+8UFRWl7NmzK0+ePHrsscfc+pm8DHLdunWqXbu2QkJC9Oabb0qS1q5dq0aNGikiIkLZs2dXiRIl9PTTT1+zh1eT3M/Y2FgdPXpUknTq1Cm9+OKLzr8jpUqV0nvvveeyZO56/bhSeHi4hg0bpl9++UWjRo2SJE2fPl2zZs3S4MGDVbBgQSUlJWno0KGqUKGCgoODlT9/fnXp0kUnT550eayZM2fq/vvvV6FChRQUFKSSJUuqf//+SkxMTHUPASAlzAQByJKMMWrevLmWLl2qjh07qnLlypo/f75effVV7d+/Xx9//LEka1ldp06dVL16dXXu3FmSVLJkSUnSmjVr9Ouvv+qxxx5TkSJFtGvXLn3++eeqW7euNm3adMM/ZS5RooSefPJJjRw5Um+88Ua6zgY9+uijKleunAYPHqyffvpJ7777rvLkyaMvv/xS9913n9577z2NHz9er7zyiqpVq6batWu7fP+AAQPkcDj0+uuv68iRIxo6dKgaNGigDRs2KHv27JKspWhNmjRRVFSUevfuLT8/P40ePVr33XefVq5cqerVq7s8ZuvWrVW6dGkNHDjwmp+/OXz4sGrVqqVz586pe/fuyps3r7799ls1b95cU6ZM0YMPPqjatWtr3LhxeuKJJxQdHa0nn3zymv2YNWuWJF11XEBAgNq2bau+ffvql19+UYMGDZz3jR49WhcuXFDnzp0VFBSkPHnyaOPGjWrYsKEiIyPVp08fJSQkqHfv3sqfP7/bYw8YMEDvvPOOHnnkEXXq1ElHjx7V8OHDVbt2ba1fv95lJuv48eNq0qSJHnvsMbVr10758+fXkSNHnM/1xhtvKFeuXNq1a5emTZt2zdd8LTt27JC/v79y5cqlc+fOqU6dOtq/f7+6dOmiW265Rb/++qt69uypgwcPum02kVI/riZ5ydvrr7+u+vXr64UXXlCtWrXUpUsXSdas1JgxY9ShQwd1795dO3fu1Keffqr169frl19+cc5SjRkzRjly5FCPHj2UI0cOLVmyRL169VJMTIw++OADl+dMqYcAcFUGALKArl27msv/SZsxY4aRZN59912Xca1atTIOh8Ns27bNeSw0NNS0b9/e7THPnTvndmzVqlVGkhk7dqzz2NKlS40ks3Tp0mvWOHr0aCPJrFmzxmzfvt0EBASY7t27O++vU6eOqVChgvP2zp07jSQzevRot8eSZHr37u283bt3byPJdO7c2XksISHBFClSxDgcDjN48GDn8ZMnT5rs2bO7vObk11C4cGETExPjPP7DDz8YSWbYsGHGGGOSkpJM6dKlTaNGjUxSUpJLr0qUKGGio6PdamrTps01+5LsxRdfNJLMypUrncfOnDljSpQoYYoXL24SExNdXn/Xrl2v+5gtW7Y0kszJkyevOmbatGlGkvnkk0+MMZf6HhYWZo4cOeL2eMHBwWb37t3OY5s2bTL+/v4u59+uXbuMv7+/GTBggMv3b9y40QQEBLgcr1OnjpFkvvjiC5ex06dPd54vaVWnTh1z2223maNHj5qjR4+azZs3m+7duxtJplmzZsYYY/r3729CQ0PNf//95/K9b7zxhvH39zd79uy5bj+uZdeuXSY0NNTkyZPHBAYGmo0bNxpjjFm5cqWRZMaPH+8yft68eW7HU/o72KVLFxMSEmIuXLjg8npT6iEAXA3L4QBkSXPmzJG/v7+6d+/ucvzll1+WMUZz58697mMkz3xIUnx8vI4fP65SpUopV65c+uOPP26qvltvvVVPPPGEvvrqKx08ePCmHutynTp1cn7t7++vqlWryhijjh07Oo/nypVLZcuW1Y4dO9y+/8knn1TOnDmdt1u1aqWCBQtqzpw5kqQNGzZo69atatu2rY4fP65jx47p2LFjio2NVf369bVixQq33ceeffbZVNU+Z84cVa9e3WXJXI4cOdS5c2ft2rXrqsuvruXMmTOS5PKarpR8X0xMjMvxhx9+WJGRkc7biYmJmj9/vlq2bKlbbrnFebxcuXJq1KiRy/dOmzZNSUlJeuSRR5w9OnbsmAoUKKDSpUtr6dKlLuODgoLUoUMHl2PJM0WzZ89WfHx8Kl/xJf/++68iIyMVGRmpcuXKafjw4br//vv1zTffSJImT56se++9V7lz53apsUGDBkpMTNSKFSuu2Y/rKVasmHr37q0TJ06oR48ezp0PJ0+erPDwcEVHR7s8b1RUlHLkyOHSm8v/Dp45c0bHjh3Tvffeq3Pnzunff/91eb6UeggAV5NlQtCKFSvUrFkzFSpUSA6H44a2uzXG6MMPP1SZMmUUFBSkwoULa8CAAelfLACP2717twoVKuT25jd5t7jdu3df9zHOnz+vXr16OT8vERERocjISJ06dUqnT5++6RrffvttJSQkpOtOXZe/OZesz2cEBwcrIiLC7fiVn7+QpNKlS7vcdjgcKlWqlPNzUFu3bpVkbTaQ/AY7+deoUaMUFxfn1psSJUqkqvbdu3erbNmybsfT8md2peQ//+QwlJKrBaUr6z569KjOnz/v1iNJbnVv3bpVxhiVLl3arU+bN2/WkSNHXMYXLlzYbZOBOnXq6OGHH1bfvn0VERGhFi1aaPTo0YqLi7vOq7YUL15cCxcu1KJFi/Tzzz/r0KFDmj17tvNc2Lp1q+bNm+dWX/KSwCtrTO2f4+WqVasmSapatarz2NatW3X69Gnly5fP7bnPnj3r8rz//POPHnzwQYWHhyssLEyRkZHOzR6uPM9S6iEAXE2W+UxQbGys7rjjDj399NN66KGHbugxXnjhBS1YsEAffvihbr/9dp04cUInTpxI50oBZBbPP/+8Ro8erRdffFE1a9ZUeHi4HA6HHnvssXS51sqtt96qdu3a6auvvtIbb7zhdv/VPvB/5YfCL5fSNs9X2/rZ3MD1cZJf9wcffKDKlSunOCZHjhwuty//aX5GK1eunGbMmKG//vrL7fNPyf766y9JUvny5V2O30zdSUlJcjgcmjt3bor9T02Pki9eu3r1as2aNUvz58/X008/rSFDhmj16tVuj3Gl0NBQl884pVRjdHS0XnvttRTvL1OmzHVrvBFJSUnKly+fxo8fn+L9ybNNp06dUp06dRQWFqZ+/fqpZMmSCg4O1h9//KHXX3/d7e+gnecZgMwny4SgJk2aqEmTJle9Py4uTm+99Za+//57nTp1ShUrVtR7772nunXrSpI2b96szz//XH///bfzJ3o38lMvAN6hWLFiWrRokc6cOePyE/7kJTTFihVzHrta2JgyZYrat2/vspPahQsXdOrUqXSr8+2339Z3332n9957z+2+3LlzS5Lb893IjEhqJc/0JDPGaNu2bapUqZKkS5tGhIWFXfMN9o0oVqyYtmzZ4nY8pT+z1HrggQc0aNAgjR07NsUQlJiYqAkTJih37ty6++67r/lYkZGRyp49u1uPJLnVXbJkSRljVKJECbcwkVZ33XWX7rrrLg0YMEATJkzQ448/rokTJ7osfbwRJUuW1NmzZ9P9zzE1z7to0SLdfffd1wwuy5Yt0/HjxzVt2jSXP7udO3dmRJkAsrgssxzuerp166ZVq1Zp4sSJ+uuvv9S6dWs1btzY+Z/ZrFmzdOutt2r27NkqUaKEihcvrk6dOjETBGRSTZs2VWJioj799FOX4x9//LEcDofLD01CQ0NTDDb+/v5usyXDhw+/5kxMWpUsWVLt2rXTl19+qUOHDrncFxYWpoiICLfPZnz22Wfp9vxXGjt2rMvSsSlTpujgwYPOfkVFRalkyZL68MMPdfbsWbfvT956+UY0bdpUv//+u1atWuU8Fhsbq6+++krFixd3m6lJjVq1aqlBgwYaPXq0Zs+e7Xb/W2+9pf/++0+vvfbadWcS/P391ahRI82YMUN79uxxHt+8ebPmz5/vMvahhx6Sv7+/+vbt63YOGWN0/Pjx69Z+8uRJt+9Nnn1L7ZK4a3nkkUe0atUqt9olK3gnJCTc9HNc7XkTExPVv39/t/sSEhKcfxeTZ9Au78HFixc9ev4D8B1ZZiboWvbs2aPRo0drz549zq1oX3nlFc2bN0+jR4/WwIEDtWPHDu3evVuTJ0/W2LFjlZiYqJdeekmtWrXSkiVLbH4FANKqWbNmqlevnt566y3t2rVLd9xxhxYsWKCZM2fqxRdfdM5oSNYb+0WLFumjjz5SoUKFVKJECdWoUUMPPPCAxo0bp/DwcJUvX16rVq3SokWLlDdv3nSt9a233tK4ceO0ZcsWVahQweW+Tp06afDgwerUqZOqVq2qFStW6L///kvX579cnjx5dM8996hDhw46fPiwhg4dqlKlSumZZ56RJPn5+WnUqFFq0qSJKlSooA4dOqhw4cLav3+/li5dqrCwMOe21Gn1xhtv6Pvvv1eTJk3UvXt35cmTR99++6127typqVOnys/vxn5uN3bsWNWvX18tWrRQ27Ztde+99youLk7Tpk3TsmXL9Oijj+rVV19N1WP17dtX8+bN07333qvnnntOCQkJGj58uCpUqOBcVidZ4fbdd99Vz549tWvXLrVs2VI5c+bUzp07NX36dHXu3FmvvPLKNZ/r22+/1WeffaYHH3xQJUuW1JkzZzRy5EiFhYWpadOmN9SLy7366qv68ccf9cADD+ipp55SVFSUYmNjtXHjRk2ZMkW7du1y+yxZeqhTp466dOmiQYMGacOGDWrYsKECAwO1detWTZ48WcOGDVOrVq1Uq1Yt5c6dW+3bt1f37t3lcDg0bty4G1rGCQBX8okQtHHjRiUmJrotSYiLi3O+mUlKSlJcXJzGjh3rHPf1118rKipKW7ZsSfHDugC8l5+fn3788Uf16tVLkyZN0ujRo1W8eHF98MEHevnll13GfvTRR+rcubPefvttnT9/Xu3bt1eNGjU0bNgw+fv7a/z48bpw4YLuvvtuLVq0yG0nsJtVqlQptWvXTt9++63bfb169dLRo0c1ZcoU/fDDD2rSpInmzp2rfPnypWsNyd5880399ddfGjRokM6cOaP69evrs88+c7kmUt26dbVq1Sr1799fn376qc6ePasCBQqoRo0azuvA3Ij8+fPr119/1euvv67hw4frwoULqlSpkmbNmqX777//hh+3YMGC+v333zVkyBBNnjxZU6dOVUBAgCpVqqQxY8boySefvOYFVy9XqVIlzZ8/Xz169FCvXr1UpEgR9e3bVwcPHnQJQZIV6sqUKaOPP/5Yffv2lSQVLVpUDRs2TPHCrVeqU6eOfv/9d02cOFGHDx9WeHi4qlevrvHjx6fLcu2QkBAtX75cAwcOdP4AMCwsTGXKlFHfvn0VHh5+089xNV988YWioqL05Zdf6s0331RAQICKFy+udu3aOZcl5s2bV7Nnz9bLL7+st99+W7lz51a7du1Uv379dP87CMD3OEwW/JGKw+HQ9OnT1bJlS0nSpEmT9Pjjj+uff/5x+4Bqjhw5VKBAAfXu3VsDBw502Yb0/PnzCgkJ0YIFCxQdHZ2RLwEAAACAh/jETFCVKlWUmJioI0eO6N57701xzN13362EhARt377duUwmecnJjXwYFwAAAIB3yjIzQWfPntW2bdskWaHno48+Ur169ZQnTx7dcsstateunX755RcNGTJEVapU0dGjR7V48WJVqlRJ999/v5KSklStWjXlyJFDQ4cOVVJSkrp27aqwsDAtWLDA5lcHAAAAIL1kmRC0bNky1atXz+14+/btNWbMGMXHx+vdd9/V2LFjtX//fkVEROiuu+5S3759dfvtt0uSDhw4oOeff14LFixQaGiomjRpoiFDhihPnjwZ/XIAAAAAeEiWCUEAAAAAkBo+c50gAAAAAJAIQQAAAAB8TKbeHS4pKUkHDhxQzpw5U32NBwAAAABZjzFGZ86cUaFCha57ge1MHYIOHDigokWL2l0GAAAAAC+xd+9eFSlS5JpjMnUIypkzpyTrhYaFhdlaS3x8vBYsWKCGDRsqMDDQ1lqyIvrrefTYs+ivZ9Ffz6K/nkV/PYv+epY39TcmJkZFixZ1ZoRrydQhKHkJXFhYmFeEoJCQEIWFhdl+AmRF9Nfz6LFn0V/Por+eRX89i/56Fv31LG/sb2o+JsPGCAAAAAB8CiEIAAAAgE8hBAEAAADwKYQgAAAAAD6FEAQAAADApxCCAAAAAPgUQhAAAAAAn0IIAgAAAOBTCEEAAAAAfAohCAAAAIBPIQQBAAAA8CmEIAAAAAA+hRAEAAAAwKcQggAAAACkWWKitHy5QytWFNby5Q4lJtpdUeoRggAAAACkybRpUvHiUnR0gD76qKqiowNUvLh1PDMgBAEAAABItWnTpFatpH37XI/v328dzwxBiBAEAAAAIFUSE6UXXpCMcb8v+diLL8rrl8YRggAAAABc09mz0sqVUvfu7jNAlzNG2rvXGuvNAuwuAAAAAID3OH9e+vNPae1a69eaNdLmzSnP/lzNwYOeqy89EIIAAAAAH3XxorRx46XAs3at9PffUkKC+9jCha3NEH755fqPW7BgupearghBAAAAgA9ISJA2bXINPH/+aQWhK0VGStWqSVWrXvpVsKD1WZ/ixa1NEFKaGXI4pCJFpHvv9fjLuSmEIAAAACCLSUqStmxxDTzr11tL3a6UO7dr2KlWzQoyDof7WH9/adgwaxc4h8M1CCWPHzrUGufNCEEAAABAJmaMtGOH9dmd5MCzbp21mcGVcuaUoqJcA0+JEikHnqt56CFpyhRrl7jLN0koUsQKQA89dNMvyeMIQQAAAEAmkbz72uWBZ+1a6dQp97HZs0t33uk6y1OmjOSXDvtDP/SQ1KKFtHRpgubO3aAmTSqrXr0Ar58BSkYIAgAAALzUwYPugefoUfdx2bJJlSu7Bp5y5aQAD77b9/eX6tQxio3drzp17sg0AUgiBAEAAABe4ehRaxnb5aHnwAH3cQEB0u23uwaeihWtIITUIQQBAAAAGezUKffAs3u3+zg/P2tG5/Kd2ipVspa64cYRggAAAAAPOnPG2pkt+cKja9dK27alPLZMGdfAU7mylCNHhpbrEwhBAAAAQDo5d8669s7lgefff1O+pk6JEpd2aKta1drEIDw842v2RYQgAAAA4AbExUkbN15azrZmjfTPP9YFRa9UpIhr4ImKkvLmzfiaYSEEAQAAANcRHy9t2uQaeP76yzp+pXz5LoWdatWswFOgQMbXjKsjBAEAAACXSUyUtmxx3ZZ6/XrpwgX3sXnyuF54tGpVqXDhtF18FBmPEAQAAACfZYy1ScHlgeePP6SzZ93HhoVZszqXB57ixQk8mREhCAAAAD7BGGsb6ssDz9q10unT7mNDQqyNCi6f5SlVytqyGpkfIQgAAABZ0v790urVDk2adJs+/9xf69ZJx465jwsKsraivjzw3Hab5O+f4SUjgxCCAAAAkOkdOeI+w3PwoGS93S3rHBcQYF1sNDnwVK0qVawoBQbaVTnsQAgCAABApnLypHvg2bPHfZyfn1S+vFH+/HvUokUR1ajhr0qVpODgjK8Z3oUQBAAAAK8VE2PtzJZ84dG1a6Xt293HORxS2bKuMzyVK0vZsiVozpwNatq0kAIDWd8GCyEIAAAAXuHcOWnDBtfAs2WLtaHBlW699dIObVWrWpsYhIW5j0vpOj4AIQgAAAAZLi7Outho8oVH166V/vlHSkpyH1u0qGvgiYqyrs8D3ChCEAAAADwqPt4KOJcHno0bU56lyZ/fCjzJoScqyjoGpCdCEAAAANJNYqL077+XlrOtWWMtcYuLcx+bN6/rhUerVpUKFeLio/A8QhAAAABuSFKStG2ba+BZv16KjXUfGx5uzepcHniKFSPwwB6EIAAAAFyXMdKuXa7bUq9bJ50+7T42NNTaqODyWZ6SJa0tqwFvQAgCAACAC2Ok/fvdr8Vz/Lj72OBgayvqywNP2bKSP7tRw4sRggAAAHzc4cPugefQIfdxgYFSpUqXlrNVqyaVL28dBzITQhAAAIAPOX7cWsZ2eeDZu9d9nL+/VKGCa+C5/XYpKCjjawbSGyEIAAAgi4qJcQ88O3a4j3M4pNtuuxR4qla1lriFhGR4yUCGIAQBAABkAbGx1s5slweeLVtSHluqlGvgufNOKWfOjK0XsJOtIahPnz7q27evy7GyZcvq33//takiAAAA73fhgvTXX5cuPLp2rbRpk7Vl9ZWKFXMNPFFRUu7cGV8z4E1snwmqUKGCFi1a5LwdEGB7SQAAAF4jPl76+2/XwLNxo5SQ4D62YEHX6/BERUn58mV8zYC3sz1xBAQEqECBAqkaGxcXp7jLLjccExMjSYqPj1d8fLxH6kut5Oe3u46siv56Hj32LPrrWfTXs+ivZ13e34QE6d9/pT/+cGjtWofWrXPor78ciotzv6JoRIRR1apGd95pFBVl/SpUKKXH9/Qr8G6cv57lTf1NSw0OY4zxYC3X1KdPH33wwQcKDw9XcHCwatasqUGDBumWW2656vgrl89J0oQJExTCJ/cAAEAmkpQkHTyYQ9u25dLWrbm0fXsu7dgRrrg4959Rh4ZeVKlSp1Sq1CmVLGn9Hhl5Xg73bAT4rHPnzqlt27Y6ffq0wsLCrjnW1hA0d+5cnT17VmXLltXBgwfVt29f7d+/X3///bdypvDpvJRmgooWLapjx45d94V6Wnx8vBYuXKjo6GgFsll+uqO/nkePPYv+ehb99Sz6e/OMkXbulNatczh//fGHQ2fOuKeYHDmMqlRxneUpWVIEnhvE+etZ3tTfmJgYRUREpCoE2bocrkmTJs6vK1WqpBo1aqhYsWL64Ycf1LFjR7fxQUFBCkphc/rAwEDbm57Mm2rJiuiv59Fjz6K/nkV/PYv+po4x0r59lz6/k/xZnpMn3ccGB0uVKycpImKnHnqomO66K0Blyjjk70/iSW+cv57lDf1Ny/Pb/pmgy+XKlUtlypTRtm3b7C4FAAAgVQ4dcg88R464jwsMlO6449KFR6tWlcqXl4xJ1Jw5f6tp01vEe3QgY3hVCDp79qy2b9+uJ554wu5SAAAA3Bw75nrx0TVrpP373cf5+0sVK7oGnooVpRQWtPj8xgWAHWwNQa+88oqaNWumYsWK6cCBA+rdu7f8/f3Vpk0bO8sCAADQ6dPugWfXLvdxDodUrtylbamrVbNmfLJnz/CSAaSSrSFo3759atOmjY4fP67IyEjdc889Wr16tSIjI+0sCwAA+JizZ6X16y8FnrVrpf/+S3ls6dKugadKFSlHjoytF8DNsTUETZw40c6nBwAAPuj8eenPP10Dz+bN1pbVVype3DXw3HmnlCtXRlcMIL151WeCAAAA0tPFi9LGja6B5++/pYQE97GFC7sGnqgoKSIi42sG4HmEIAAAkCUkJFgzOsk7tK1da834XLzoPjYy8tKGBcm/ChbM+JoB2IMQBAAAMp2kJOszO5cHnvXrraVuV8qd2zXsVKsmFSnCxUcBX0YIAgAAXs0YaccO18Dzxx/SmTPuY3PmtJaxXR54SpQg8ABwRQgCAABewxhp717XC4+uXSudOuU+Nnt2a6OCy2d5ypSR/PwyvGwAmQwhCAAA2ObgQffAc/So+7hs2aTKlV0DT7lyUgDvZADcAP7pAAAAGeLo0UsXH00OPQcOuI8LCJBuv9018FSsaAUhAEgPhCAAAJDuTp1yDzy7d7uP8/OzZnQu36mtUiVrqRsAeAohCAAA3JQzZ6yd2ZKXs61ZI23blvLYMmVcA0/lylKOHBlaLgAQggAAQOqdPy9t2OAaeP7919rQ4EolSlzaoa1qVWsTg/DwDC8ZANwQggAAQIri4qSNG6XffvPTjBmV1atXgP75R0pMdB9bpIhr4ImKkvLmzfiaASA1CEEAAEAJCdI//1ya4Vm7VvrrL+niRUnyl1TMOTZfvkthp1o1K/AUKGBX5QCQdoQgAAB8TGKitGWLa+BZv166cMF9bJ48UlRUksLDt+nRR2/VXXcFqHBhLj4KIHMjBAEAkIUZY21ScHng+eMP6exZ97FhYdaszuXL2ooXlxISEjVnzmY1bVpCgYEZ/hIAIN0RggAAyCKMkfbscb3w6Lp11nbVVwoJsTYqSN6lrVo1qVQpa8tqAMjqCEEAAGRSBw64Bp61a6Vjx9zHBQVZW1FfHnhuu03y98/wkgHAKxCCAADIBI4csWZ1Lg89Bw+6jwsIsC42mhx4qlaVKlYUy9gA4DKEIAAAvMzJk+6BZ88e93F+flKFCq6Bp1IlKTg442sGgMyEEAQAgI3OnLE2Kki+8OjatdL27e7jHA6pbFnXwFO5shQamuElA0CmRwgCACCDnDsnbdjgGni2bLE2NLjSrbde2qGtalVrE4OwsAwvGQCyJEIQAAAeEBdnXWw0eTnbmjXWxUiTktzHFi3qGniioqzr8wAAPIMQBADATYqPtwLO5YFn40br+JXy57cCT3LoiYqyjgEAMg4hCACANEhMlP7913Vb6g0bpAsX3Mfmzet64dGqVaVChazP9wAA7EMIAgDgKpKSpG3bXAPPH39IsbHuY8PDrVmdywNPsWIEHgDwRoQgAABkbU6we7frttTr1kmnT7uPDQ21Niq4fJanZElry2oAgPcjBAEAMrXERGn5codWrCis0FCH6tWT/P2v/T3GSAcOuAaetWul48fdxwYHW1tRXx54ypa9/nMAALwXIQgAkGlNmya98IK0b1+ApKr66COpSBFp2DDpoYcujTtyxHVb6rVrpUOH3B8vMNC62GjycrZq1aTy5a3jAICsgxAEAMiUpk2TWrVyv8bO/v3Sww9LbdtK589bgWfvXvfv9/eXKlRwDTy33y4FBWVM/QAA+xCCAACZTmKiNQOU0kVGk49NmHDpmMMh3XbbpcBTtaq1xC0kJEPKBQB4GUIQACDTWblS2rfv+uOefVZ67DFrE4OcOT1fFwAgcyAEAQAynYMHUzeudm2pTh3P1gIAyHzYzBMAkOnkzp26cQULerYOAEDmxEwQACBTiY2VBg++9hiHw9ol7t57M6YmAEDmwkwQACDTOHtWatpUWr7cun6PZAWeyyXfHjqUa/kAAFJGCAIAZApnzkhNmkgrVkhhYdLSpdLUqVLhwq7jihSRpkxxvU4QAACXYzkcAMDrxcRYAejXX6XwcGnBAql6deu+Fi2kpUsTNHfuBjVpUln16gUwAwQAuCZCEADAq50+LTVuLK1eLeXKJS1caF3nJ5m/v1SnjlFs7H7VqXMHAQgAcF2EIACA1zp1SmrUSPr9d2tHuEWLrGv+AABwMwhBAACvdPKk1LChtHatlDevFYAqV7a7KgBAVkAIAgB4nRMnpOho6Y8/pIgIafFiqVIlu6sCAGQVhCAAgFc5flxq0EDasEGKjJSWLJEqVrS7KgBAVsIW2QAAr3HsmFS/vhWA8uWztsEmAAEA0hshCADgFY4cke67T/rzT6lAAWnZMqlCBburAgBkRSyHAwDY7vBhKwBt2iQVLGjNAJUta3dVAICsipkgAICtDh2S6tWzAlChQtYMEAEIAOBJhCAAgG0OHJDq1pU2b5aKFJGWL5fKlLG7KgBAVsdyOACALfbvt2aAtm6Viha1lsCVLGl3VQAAX8BMEAAgw+3bZ80Abd0qFStmzQARgAAAGYUQBADIUHv2SHXqSNu2SSVKWAGoRAm7qwIA+BJCEAAgw+zebc0A7dgh3XqrtQlCsWJ2VwUA8DWEIABAhti505oB2rlTKlXKmgG65Ra7qwIA+CJCEADA43bssGaAdu+2dn9btszaDQ4AADuwOxwAwKO2bbN2gdu3z7r+z9Kl1gVRAQCwCzNBAACP2brVmgHat08qV86aASIAAQDsRggCAHjEli3WZ4D275cqVLBmgAoUsLsqAAAIQQAAD9i82ZoBOnhQuv12ackSKX9+u6sCAMDCZ4IAAOlq0ybpvvukw4elSpWkxYuliAi7qwIA4BJmggAA6ebvv60ZoMOHpcqVrRkgAhAAwNsQggAA6eKvv6xd4I4ele6805oBypvX7qoAAHBHCAIA3LQNG6wlcMeOSVWrSosWSXny2F0VAAApIwQBAG7KH39I9etLx49L1atLCxdKuXPbXRUAAFdHCAIA3LB166wAdOKEdNdd0oIFUq5cdlcFAMC1EYIAADdkzRorAJ06JdWqJc2fL4WH210VAADXRwgCAKTZb79JDRpIp09L99wjzZsnhYXZXRUAAKlDCAIApMmqVVJ0tBQTI9WuLc2dK+XMaXdVAACkHiEIAJBqv/wiNWwonTljXQ9ozhwpRw67qwIAIG28JgQNHjxYDodDL774ot2lAABSsHKl1KiRdPastR32Tz9JoaF2VwUAQNp5RQhas2aNvvzyS1WqVMnuUgAAKVi+XGrSRIqNtT4LNGuWFBJid1UAANwY20PQ2bNn9fjjj2vkyJHKzYUlAMDrLFlyKQA1bCj9+CMBCACQuQXYXUDXrl11//33q0GDBnr33XevOTYuLk5xcXHO2zExMZKk+Ph4xcfHe7TO60l+frvryKror+fRY8/KrP1dvNihBx/014ULDjVunKQffkhUQIDkbS8js/Y3s6C/nkV/PYv+epY39TctNTiMMcaDtVzTxIkTNWDAAK1Zs0bBwcGqW7euKleurKFDh6Y4vk+fPurbt6/b8QkTJiiEH0sCQLpavz5SgwbV0MWL/qpa9ZBef32NAgOT7C4LAIAUnTt3Tm3bttXp06cVdp3rNtgWgvbu3auqVatq4cKFzs8CXS8EpTQTVLRoUR07duy6L9TT4uPjtXDhQkVHRyswMNDWWrIi+ut59NizMlt/5893qFUrf8XFOXT//UmaODFRQUF2V3V1ma2/mQ399Sz661n017O8qb8xMTGKiIhIVQiybTncunXrdOTIEd15553OY4mJiVqxYoU+/fRTxcXFyd/f3+V7goKCFJTC/8KBgYG2Nz2ZN9WSFdFfz6PHnpUZ+vvTT9LDD0sXL0otW0qTJvkpWzbbP0KaKpmhv5kZ/fUs+utZ9NezvKG/aXl+20JQ/fr1tXHjRpdjHTp00G233abXX3/dLQABADxv1iwrAMXHW79//73EewYAQFZjWwjKmTOnKlas6HIsNDRUefPmdTsOAPC8mTOl1q2tANS6tTR+PAEIAJA1ZY71DQAAj5o2TWrVygpAjz0mTZhAAAIAZF22b5F9uWXLltldAgD4nClTrOCTmCi1bSt9+60U4FX/OwAAkL6YCQIAHzZp0qUA9MQT0tixBCAAQNZHCAIAH/X999bMT2Ki9NRT0ujREnvSAAB8ASEIAHzQd99J7dpJSUnS009LX39NAAIA+A5CEAD4mLFjpSeftALQM89II0dKfvxvAADwIfy3BwA+ZPRoa+mbMdKzz0pffEEAAgD4Hv7rAwAf8fXXUseOVgB67jnps88IQAAA38R/fwDgA776SurUyQpAzz8vffqp5HDYXRUAAPYgBAFAFvf551KXLtbXL74oDRtGAAIA+DZCEABkYSNGWEvfJOnll6WPPiIAAQBACAKALOqTT6Ru3ayvX3tN+uADAhAAABIhCACypI8/ll54wfq6Z09p8GACEAAAyQhBAJDFfPih1KOH9fXbb0sDBhCAAAC4HCEIALKQ996TXn3V+rp3b6lfPwIQAABXIgQBQBYxcKD0xhvW1337Sn36EIAAAEgJIQgAsoD+/aW33rK+fvddqVcve+sBAMCbBdhdAADg5iTP+kjSoEGXZoMAAEDKCEEAkEkZY33up39/6/b771/6PBAAALg6QhAAZELGWDu/DRxo3R4y5NKOcAAA4NoIQQCQyRhjLXl7/33r9scfSy++aGtJAABkKoQgAMhEjLGWvA0ZYt3+5BPp+eftrQkAgMyGEAQAmYQx1pK3oUOt2yNGSM89Z2tJAABkSoQgAMgEjLGWvH3yiXX7iy+kLl1sLQkAgEyLEAQAXs4Ya8nbiBHW7a++kp55xt6aAADIzAhBAODFkpKkrl2tmR+HQxo1Snr6aburAgAgcyMEAYCXSkqSnn1WGjnSCkCjR0vt29tdFQAAmR8hCAC8UFKS1Lmz9PXXkp+f9O23Urt2dlcFAEDWQAgCAC+TmCh16iSNGWMFoHHjpLZt7a4KAICsgxAEAF4kMVHq0MEKPv7+0vjx0qOP2l0VAABZCyEIALxEQoL01FNW8PH3l77/Xmrd2u6qAADIeghBAOAFEhKkJ56QJk6UAgKkSZOkhx6yuyoAALImQhAA2Cw+3tr04IcfpMBA6/eWLe2uCgCArIsQBAA2io+X2rSRpk61AtDUqVKzZnZXBQBA1kYIAgCbXLwoPfaYNH26lC2bNG2adP/9dlcFAEDWRwgCABtcvCg98og0c6YUFGQFoSZN7K4KAADfQAgCgAwWFye1aiXNni0FB0szZkiNGtldFQAAvsPP7gIAwJdcuGDt+pYcgGbNIgABAJDRmAkCgAxy8aKfWrf21/z5UvbsVhC67z67qwIAwPcQggAgA5w/Lw0YUEN//umnkBDpp5+kunXtrgoAAN9ECAIADzt3TnrwQX/9+Wc+hYYazZnjUO3adlcFAIDv4jNBAOBBsbHSAw9IS5b4KTg4QbNnJxKAAACwGSEIADzk7Fnruj9Ll0o5cxr16fOr7r7b2F0WAAA+j+VwAOABZ85YAWjlSiksTPrpp0QdP37S7rIAAICYCQKAdBcTY134dOVKKTxcWrhQqlGDGSAAALwFIQgA0tHp01LjxtIvv0i5ckmLFknVq9tdFQAAuBzL4QAgnZw6ZV349Pffpdy5rQB05512VwUAAK5ECAKAdHDypNSwobR2rZQnjxWAqlSxuyoAAJASQhAA3KQTJ6ToaOmPP6S8eaXFi6U77rC7KgAAcDWEIAC4CcePSw0aSBs2SJGRVgC6/Xa7qwIAANdCCAKAG3TsmBWA/vxTypdPWrJEqlDB7qoAAMD1EIIA4AYcPSrVry9t3Cjlz28FoPLl7a4KAACkBltkA0AaHT4s1atnBaCCBaVlywhAAABkJmkOQd9++61++ukn5+3XXntNuXLlUq1atbR79+50LQ4AvM2hQ1YA+ucfqVAhKwDddpvdVQEAgLRIcwgaOHCgsmfPLklatWqVRowYoffff18RERF66aWX0r1AAPAWBw9aAWjzZqlIEWn5cqlMGburAgAAaZXmzwTt3btXpUqVkiTNmDFDDz/8sDp37qy7775bdevWTe/6AMAr7N8v3Xef9N9/UtGi0tKlUsmSdlcFAABuRJpngnLkyKHjx49LkhYsWKDo6GhJUnBwsM6fP5++1QGAF9i3T6pb1wpAxYpZM0AEIAAAMq80zwRFR0erU6dOqlKliv777z81bdpUkvTPP/+oePHi6V0fANhq715rCdz27VLx4tYMEP/UAQCQuaV5JmjEiBGqVauWjh49qqlTpypv3rySpHXr1qlNmzbpXiAA2GX3bqlOHSsA3XqrNQNEAAIAIPNL00xQQkKCPvnkE73++usqUqSIy319+/ZN18IAwE67dlkzQLt2WUvfli61PgsEAAAyvzTNBAUEBOj9999XQkKCp+oBANvt2GHNAO3aJZUubc0AEYAAAMg60rwcrn79+lq+fLknagEA223fbm2CsGePVLasdR2gwoXtrgoAAKSnNG+M0KRJE73xxhvauHGjoqKiFBoa6nJ/8+bN0604AMhIW7daS+D277cugLpkiVSwoN1VAQCA9JbmEPTcc89Jkj766CO3+xwOhxITE2++KgDIYFu2WNcBOnBAKl/eCkD589tdFQAA8IQ0h6CkpCRP1AEAtvn3X2sG6NAhqWJFafFiKV8+u6sCAACekubPBF3uwoUL6VUHANhi0ybrM0CHDkmVKlkzQAQgAACytjSHoMTERPXv31+FCxdWjhw5tGPHDknSO++8o6+//jrdCwQAT/n7b2sG6PBhqXJlawYoMtLuqgAAgKelOQQNGDBAY8aM0fvvv69s2bI5j1esWFGjRo1K1+IAwFM2brQC0JEjUpUqVgCKiLC7KgAAkBHSHILGjh2rr776So8//rj8/f2dx++44w79+++/6VocAHjCn39aAejYMSkqygpAefLYXRUAAMgoaQ5B+/fvV6lSpdyOJyUlKT4+Pk2P9fnnn6tSpUoKCwtTWFiYatasqblz56a1JABItfXrrV3gjh+XqlWTFi2Scue2uyoAAJCR0hyCypcvr5UrV7odnzJliqpUqZKmxypSpIgGDx6sdevWae3atbrvvvvUokUL/fPPP2ktCwCua906qX596cQJqUYNaeFCKVcuu6sCAAAZLc1bZPfq1Uvt27fX/v37lZSUpGnTpmnLli0aO3asZs+enabHatasmcvtAQMG6PPPP9fq1atVoUKFtJYGAFe1Zo3UsKF06pRUs6Y0b54UFmZ3VQAAwA5pDkEtWrTQrFmz1K9fP4WGhqpXr1668847NWvWLEVHR99wIYmJiZo8ebJiY2NVs2bNFMfExcUpLi7OeTsmJkaSFB8fn+aleOkt+fntriOror+el5V7/PvvDjVt6q+YGIdq1UrSrFmJyp5dysiXmpX76w3or2fRX8+iv55Ffz3Lm/qblhocxhjjwVqua+PGjapZs6YuXLigHDlyaMKECWratGmKY/v06aO+ffu6HZ8wYYJCQkI8XSqATOjff3Orb9+aOn8+UOXLH9M77/ym7NkT7C4LAACks3Pnzqlt27Y6ffq0wq6z3MP2EHTx4kXt2bNHp0+f1pQpUzRq1CgtX75c5cuXdxub0kxQ0aJFdezYseu+UE+Lj4/XwoULFR0drcDAQFtryYror+dlxR7/+qtDDzzgr7NnHapdO0kzZiQqRw57asmK/fUm9Nez6K9n0V/Por+e5U39jYmJUURERKpCUKqWw+XOnVsOhyNVT37ixIlUjUuWLVs2525zUVFRWrNmjYYNG6Yvv/zSbWxQUJCCgoLcjgcGBtre9GTeVEtWRH89L6v0eOVK6f77pdhYazvsWbP8FBqa5r1g0l1W6a+3or+eRX89i/56Fv31LG/ob1qeP1UhaOjQoc6vjx8/rnfffVeNGjVyfnZn1apVmj9/vt555520VZqCpKQkl9keAEir5csvBaAGDaSZMyVWzAIAgGSpCkHt27d3fv3www+rX79+6tatm/NY9+7d9emnn2rRokV66aWXUv3kPXv2VJMmTXTLLbfozJkzmjBhgpYtW6b58+en4SUAwCVLl0oPPCCdO2ftBjdjhpQ9u91VAQAAb5LmtSHz589X48aN3Y43btxYixYtStNjHTlyRE8++aTKli2r+vXra82aNZo/f/5N7TIHwHctXmzNAJ07JzVubM0AEYAAAMCV0rxFdt68eTVz5ky9/PLLLsdnzpypvHnzpumxvv7667Q+PQCkaMECqUUL6cIFKwhNmSIFB9tdFQAA8EZpDkF9+/ZVp06dtGzZMtWoUUOS9Ntvv2nevHkaOXJkuhcIANczb57UsqUUFyc1ayZNniylsIcKAACApBsIQU899ZTKlSunTz75RNOmTZMklStXTj///LMzFAFARpkzR3rwQeniRSsITZokZctmd1UAAMCbpSkExcfHq0uXLnrnnXc0fvx4T9UEAKkye7b08MNWAHroIWniRIndTwEAwPWkaWOEwMBATZ061VO1AECqzZxpBZ+LF6XWrQlAAAAg9dK8O1zLli01Y8YMD5QCAKkzfbrUqpUUHy89+qg0YQIBCAAApF6aPxNUunRp9evXT7/88ouioqIUGhrqcn/37t3TrTgAuNLUqdJjj0kJCVLbttK330oBaf6XDAAA+LI0v3X4+uuvlStXLq1bt07r1q1zuc/hcBCCAHjMDz9YwScxUWrXThozRvL3t7sqAACQ2aQ5BO3cudMTdQDANU2caAWfxESpfXvp668JQAAA4Mak+TNByY4dO6Zjx46lZy0AkKLx46XHH7cCUIcOBCAAAHBz0hSCTp06pa5duyoiIkL58+dX/vz5FRERoW7duunUqVMeKhGALxs3TnrySSkpSerUSRo1igAEAABuTqqXw504cUI1a9bU/v379fjjj6tcuXKSpE2bNmnMmDFavHixfv31V+XOndtjxQLwLWPGSE8/LRkjdekiffaZ5HfD89cAAACWVIegfv36KVu2bNq+fbvy58/vdl/Dhg3Vr18/ffzxx+leJADf88031syPMdL//id9+ikBCAAApI9Uv6WYMWOGPvzwQ7cAJEkFChTQ+++/r+nTp6drcQB808iRUseOVgDq1k0aMYIABAAA0k+q31YcPHhQFSpUuOr9FStW1KFDh9KlKAC+64svpM6dra9feEH65BPJ4bC3JgAAkLWkOgRFRERo165dV71/586dypMnT3rUBMBHjRhhLX2TpB49pI8/JgABAID0l+oQ1KhRI7311lu6ePGi231xcXF655131Lhx43QtDoDvGD7cWvomSa++Kn34IQEIAAB4Rpo2RqhatapKly6trl276rbbbpMxRps3b9Znn32muLg4jRs3zpO1Asiihg6VXnrJ+vqNN6SBAwlAAADAc1IdgooUKaJVq1bpueeeU8+ePWWMkSQ5HA5FR0fr008/VdGiRT1WKICsacgQ6ZVXrK/fekvq358ABAAAPCvVIUiSSpQooblz5+rkyZPaunWrJKlUqVJ8FgjADXnvPWvmR5J69ZL69CEAAQAAz0tTCEqWO3duVa9ePb1rAeBDBg60Zn4kK/z07m1rOQAAwIdw5Q0AGa5//0sBqH9/AhAAAMhYNzQTBAA3qm9fa+ZHsmaDeva0tRwAAOCDCEEAMoQx1oxP//7W7ffek157zd6aAACAbyIEAfA4Y6S337ZmfiTrGkAvv2xvTQAAwHelKgT9+OOPqX7A5s2b33AxALIeY6wlb++9Z93+6KNL1wQCAACwQ6pCUMuWLVP1YA6HQ4mJiTdTD4AsxBhryduHH1q3P/lEev55e2sCAABIVQhKSkrydB0AshhjrCVvH39s3R4xQnruOXtrAgAAkPhMEAAPMMZa8jZsmHX7iy+kLl3srQkAACDZDYWg2NhYLV++XHv27NHFixdd7uvevXu6FAYgczJG6t5d+vRT6/ZXX0nPPGNvTQAAAJdLcwhav369mjZtqnPnzik2NlZ58uTRsWPHFBISonz58hGCAB+WlCR16yZ9/rnkcEijRklPP213VQAAAK780voNL730kpo1a6aTJ08qe/bsWr16tXbv3q2oqCh9mPzpZwA+JylJ+t//LgWg0aMJQAAAwDulOQRt2LBBL7/8svz8/OTv76+4uDgVLVpU77//vt58801P1AjAyyUlWZ/5+eoryc9P+vZbqX17u6sCAABIWZpDUGBgoPz8rG/Lly+f9uzZI0kKDw/X3r1707c6AF4vMVHq1Mla+ubnJ40bJz3xhN1VAQAAXF2aPxNUpUoVrVmzRqVLl1adOnXUq1cvHTt2TOPGjVPFihU9USMAL5WYaC15GztW8veXvvtOeuwxu6sCAAC4tjTPBA0cOFAFCxaUJA0YMEC5c+fW//73Px09elRffvlluhcIwDslJkpPPXUpAH3/PQEIAABkDmmeCapatarz63z58mnevHnpWhAA75eQID35pBV8AgKkiROlhx+2uyoAAIDUSfNM0H333adTp065HY+JidF9992XHjUB8GIJCVK7dpcC0A8/EIAAAEDmkuaZoGXLlrldIFWSLly4oJUrV6ZLUQC8U3y81LatNGWKFBho/d68ud1VAQAApE2qQ9Bff/3l/HrTpk06dOiQ83ZiYqLmzZunwoULp291ALzGxYtSmzbStGlStmzS1KnSAw/YXRUAAEDapToEVa5cWQ6HQw6HI8Vlb9mzZ9fw4cPTtTgA3uHiRemRR6SZM6WgICsINW1qd1UAAAA3JtUhaOfOnTLG6NZbb9Xvv/+uyMhI533ZsmVTvnz55O/v75EiAdgnLk5q3VqaNcsKQDNnSo0a2V0VAADAjUt1CCpWrJgkKSkpyWPFAPAuFy5IrVpJP/0kBQdLP/4oRUfbXRUAAMDNSfPGCJK0fft2DR06VJs3b5YklS9fXi+88IJKliyZrsUBsM+FC9KDD0rz5knZs1szQfXr210VAADAzUvzFtnz589X+fLl9fvvv6tSpUqqVKmSfvvtN1WoUEELFy70RI0AMtj581KLFlYACgmxZoIIQAAAIKtI80zQG2+8oZdeekmDBw92O/76668rmrUyQKZ27px13Z/Fi6XQUCsA1aljd1UAAADpJ80zQZs3b1bHjh3djj/99NPatGlTuhQFwB4XLvirZUt/LV4s5cghzZ1LAAIAAFlPmkNQZGSkNmzY4HZ8w4YNypcvX3rUBMAGZ89K/fvfpWXL/JQzp7UU7t577a4KAAAg/aV6OVy/fv30yiuv6JlnnlHnzp21Y8cO1apVS5L0yy+/6L333lOPHj08VigAzzlzRmre3F///BOhnDmN5s93qGZNu6sCAADwjFSHoL59++rZZ5/VO++8o5w5c2rIkCHq2bOnJKlQoULq06ePunfv7rFCAXhGTIx14dNffvFTSEi85s51qGbNG9o4EgAAIFNI9TsdY4wkyeFw6KWXXtJLL72kM2fOSJJy5szpmeoAeNTp01KTJtKqVVKuXEZvvfWrqlevZXdZAAAAHpWmH/c6HA6X24QfIPM6fVpq1Ej67Tcpd25p7twEHTp0yu6yAAAAPC5NIahMmTJuQehKJ06cuKmCAHjeqVNSw4bSmjVSnjzSokVSxYrSnDl2VwYAAOB5aQpBffv2VXh4uKdqAZABTpywAtC6dVLevNb1gO64Q4qPt7syAACAjJGmEPTYY4+xDTaQiR0/LkVHS+vXS5GRVgC6/Xa7qwIAAMhYqQ5B11sGB8C7HTsmNWgg/fmnlC+ftGSJVKGC3VUBAABkvDTvDgcg8zl6VKpfX9q4Ucqf3wpA5cvbXRUAAIA9Uh2CkpKSPFkHAA85csQKQH//LRUsaAWg226zuyoAAAD7cEVEIAs7fFi67z5p0yapUCFp6VKpTBm7qwIAALCXn90FAPCMgwelunWtAFS4sLRsGQEIAABAYiYIyJIOHJDq1ZP++08qWtSaASpZ0u6qAAAAvAMzQUAWs3+/NQP033/SLbdYM0AEIAAAgEsIQUAWsnevVKeOtHWrVLy4tHy5dOutdlcFAADgXQhBQBaxZ481A7R9u1SihDUDVLy4zUUBAAB4IUIQkAXs2mXNAO3YYS19W75cKlbM7qoAAAC8EyEIyOR27rQC0K5dUunS1gxQ0aJ2VwUAAOC9CEFAJrZ9uxWA9uyxtr9etkwqUsTuqgAAALybrSFo0KBBqlatmnLmzKl8+fKpZcuW2rJli50lAZnGtm3WZ4D27pVuu80KQIUK2V0VAACA97M1BC1fvlxdu3bV6tWrtXDhQsXHx6thw4aKjY21syzA6/33nzUDtG+fVL68dR2gggXtrgoAACBzsPViqfPmzXO5PWbMGOXLl0/r1q1T7dq1baoK8G7//ivdd5908KBUoYK0ZImUL5/dVQEAAGQetoagK50+fVqSlCdPnhTvj4uLU1xcnPN2TEyMJCk+Pl7x8fGeL/Aakp/f7jqyKvpr2bRJatQoQIcPO1SxotH8+QnKnVtKj7bQY8+iv55Ffz2L/noW/fUs+utZ3tTftNTgMMYYD9aSaklJSWrevLlOnTqln3/+OcUxffr0Ud++fd2OT5gwQSEhIZ4uEbDV7t051atXLZ0+HazixU+rX79fFRZ20e6yAAAAvMK5c+fUtm1bnT59WmFhYdcc6zUh6H//+5/mzp2rn3/+WUWusr1VSjNBRYsW1bFjx677Qj0tPj5eCxcuVHR0tAIDA22tJSvy9f5u3GjNAB075lDlykZz5yYob970fQ5f77Gn0V/Por+eRX89i/56Fv31LG/qb0xMjCIiIlIVgrxiOVy3bt00e/ZsrVix4qoBSJKCgoIUFBTkdjwwMND2pifzplqyIl/s759/Sg0bSsePS1FR0oIFDuXJ47ke+GKPMxL99Sz661n017Por2fRX8/yhv6m5flt3R3OGKNu3bpp+vTpWrJkiUqUKGFnOYDXWb/e2gTh+HGpWjVp4ULpKh+ZAwAAQCrZOhPUtWtXTZgwQTNnzlTOnDl16NAhSVJ4eLiyZ89uZ2mA7datk6KjpZMnpRo1pHnzpFy57K4KAAAg87N1Jujzzz/X6dOnVbduXRUsWND5a9KkSXaWBdhuzRqpQQMrAN11lzR/PgEIAAAgvdg6E+QlezIAXuW336RGjaTTp6VataS5cyWb9/0AAADIUmydCQLgatUqaxOE06ele+6xlsARgAAAANIXIQjwEr/+as0AxcRItWtbM0A5c9pdFQAAQNZDCAK8wM8/WwHozBmpXj1pzhwpRw67qwIAAMiaCEGAzVaskBo3ls6etTZDmD1bCg21uyoAAICsixAE2GjZMqlJEyk21vos0I8/SiEhdlcFAACQtRGCAJssXiw1bSqdO2fNBM2cKXF5LAAAAM8jBAE2WLhQeuAB6fx5KwhNny4FB9tdFQAAgG8gBAEZbP58qVkz6cIF6/dp0whAAAAAGYkQBGSguXOlFi2kuDjr9ylTpKAgu6sCAADwLYQgIIPMni21bGkFoAcflH74QcqWze6qAAAAfA8hCMgAP/4oPfSQdPGi1KqVNGkSAQgAAMAuhCDAw2bMsIJPfLz0yCPShAlSYKDdVQEAAPguQhDgQVOnSq1bWwGoTRtp/HgCEAAAgN0IQYCHTJ4sPfqolJAgPf64NHasFBBgd1UAAAAgBAEeMGmSNfOTmCg9+aT07bcEIAAAAG9BCALS2YQJUtu2VgB66inpm28kf3+7qwIAAEAyQhCQjr77TnriCSkpSerYUfr6awIQAACAtyEEAenk22+tpW9JSVLnztJXX0l+/A0DAADwOrxFA9LBN99IHTpIxkj/+5/0+ecEIAAAAG/F2zTgJo0caS19M0bq2lUaMYIABAAA4M14qwbchC++sJa+SVL37tLw4ZLDYW9NAAAAuDZCEHCDRoywlr5J0ksvSUOHEoAAAAAyA0IQcAOGD5e6dbO+fuUVacgQAhAAAEBmQQgC0mjoUGvpmyS9/rr0/vsEIAAAgMyEEASkwZAh1tI3SXrzTWnQIAIQAABAZkMIAlLp/fetpW+S9M470rvvEoAAAAAyI0IQkAqDBllL3ySpTx+pXz8CEAAAQGZFCAKu4913raVvkhV+eve2tx4AAADcHEIQcA19+1pL3yRpwIBLXwMAACDzCrC7AMAbGXNp2ZskDR58aTkcAAAAMjdCEHAFY6wZnwEDrNsffii9/LK9NQEAACD9EIKAyxhjff5n8GDr9kcfXdoSGwAAAFkDIQj4f8ZYS94++MC6PWzYpYuiAgAAIOsgBAGyAtArr1gzP5L06adS16721gQAAADPIATB5xljLXkbNsy6/fnn0rPP2lsTAAAAPIcQBJ9mjPTCC9Lw4dbtL7+UOne2tyYAAAB4FiEIPispSXr+eemzzySHQxo5UurY0e6qAAAA4GmEIPikpCTpueesmR+HQ/rmG+mpp+yuCgAAABmBEASfk5QkdekijRplBaAxY6Qnn7S7KgAAAGQUQhB8SlKS9Mwz1syPn580dqz0+ON2VwUAAICMRAiCz0hMtD7z8+23VgD67jupTRu7qwIAAEBGIwTBJyQmSh06SOPGSf7+0oQJ0iOP2F0VAAAA7EAIQpaXkCC1b28Fn4AA6fvvpVat7K4KAAAAdiEEIUtLSJCeeEKaONEKQD/8ID34oN1VAQAAwE6EIGRZ8fHWpgeTJ0uBgdbvLVrYXRUAAADsRghClnTxorXpwbRpUrZs0pQpUrNmdlcFAAAAb0AIQpZz8aK16cHMmVYAmj5datrU7qoAAADgLQhByFLi4qTWraVZs6SgIGnGDKlxY7urAgAAgDchBCHLuHDB2vXtp5+k4GBrJqhhQ7urAgAAgLchBCFLuHDB2vVt3jwpe3bpxx+lBg3srgoAAADeiBCETO/8eallS2nBAisAzZ4t3Xef3VUBAADAWxGCkKmdO2dte71okRQSIs2ZI9WpY3dVAAAA8GaEIGRasbFS8+bSkiVSaKg0d6507712VwUAAABvRwhCphQbKz3wgLRsmZQjh/VZoLvvtrsqAAAAZAaEIGQ6Z89a1/1ZuVLKmdMKQLVq2V0VAAAAMgs/uwsA0uLMGeu6PytXSmFh0sKFBCAAAACkDTNByDTOnQvQ/ff7a/VqKVcuaze4atXsrgoAAACZDSEImcLp01LfvjW1ZYufcue2ZoCiouyuCgAAAJkRIQhe79QpqWlTf23Zkkd58hgtWuRQlSp2VwUAAIDMis8EwaudPClFR0tr1vgpZ844zZ+fQAACAADATSEEwWudOCE1aCCtXStFRBj17/+r7rjD7qoAAACQ2bEcDl7p+HErAG3YIEVGSvPnJ2jPnhi7ywIAAEAWwEwQvM7Ro9J991kBKH9+64KoFSvaXRUAAACyCkIQvMqRI1YA+usvqUABKwCVL293VQAAAMhKWA4Hr3H4sBWANm2SChaUli6Vypa1uyoAAABkNcwEwSscOiTVq2cFoMKFpeXLCUAAAADwDEIQbHfggFS3rrR5s1SkiLUErnRpu6sCAABAVmVrCFqxYoWaNWumQoUKyeFwaMaMGXaWAxvs328FoC1bpFtusWaASpWyuyoAAABkZbaGoNjYWN1xxx0aMWKEnWXAJvv2WQFo61apWDErAN16q91VAQAAIKuzdWOEJk2aqEmTJnaWAJvs2WN9BmjHDqlECWsThGLF7K4KAAAAviBT7Q4XFxenuLg45+2YGOvimfHx8YqPj7erLGcNl/+Oq9u9W2rYMEA7dzp0661GCxYkqFAh6Vqto7+eR489i/56Fv31LPrrWfTXs+ivZ3lTf9NSg8MYYzxYS6o5HA5Nnz5dLVu2vOqYPn36qG/fvm7HJ0yYoJCQEA9Wh/Ry+HCI3n77bh09GqKCBc+qf/9fFBFxwe6yAAAAkMmdO3dObdu21enTpxUWFnbNsZkqBKU0E1S0aFEdO3bsui/U0+Lj47Vw4UJFR0crMDDQ1lq81fbt1gzQ3r0OlS5tzQAVLpy676W/nkePPYv+ehb99Sz661n017Por2d5U39jYmIUERGRqhCUqZbDBQUFKSgoyO14YGCg7U1P5k21eJNt26ToaGszhLJlpaVLHSpYMO19or+eR489i/56Fv31LPrrWfTXs+ivZ3lDf9Py/FwnCB73339SnTpWACpXzroOUMGCdlcFAAAAX2XrTNDZs2e1bds25+2dO3dqw4YNypMnj2655RYbK0N6+fdf6b77pIMHpQoVpMWLpfz57a4KAAAAvszWELR27VrVq1fPebtHjx6SpPbt22vMmDE2VYX0snmztQ324cPS7bdLixZJ+fLZXRUAAAB8na0hqG7duvKSfRmQzv75x5oBOnJEqlTJmgGKiLC7KgAAAIDPBMEDNm60ZoCOHJEqV5aWLCEAAQAAwHsQgpCu/vzTmgE6elS6805rBihvXrurAgAAAC4hBCHdbNhgBaBjx6SqVa3PAOXJY3dVAAAAgCtCENLFH39YAejECal6dWnhQil3brurAgAAANwRgnDT1q6V6teXTp6U7rpLWrBAypXL7qoAAACAlBGCcFN+/11q0EA6dUqqVUuaP18KD7e7KgAAAODqCEG4YatXS9HR0unT0j33SPPmSWFhdlcFAAAAXBshCDfk11+lhg2lmBipdm1p7lwpZ067qwIAAACujxCENPv5Z6lRI+nMGet6QHPmSDly2F0VAAAAkDqEIKTJihVS48bS2bPWZgizZ0uhoXZXBQAAAKQeIQiptmyZ1KSJFBtrfRZo1iwpJMTuqgAAAIC0IQQhVZYskZo2lc6ds5bCzZwpZc9ud1UAAABA2hGCcF2LFkn33y+dP28FoRkzCEAAAADIvAhBuKYFC6RmzaQLF6QHHpCmTZOCg+2uCgAAALhxhCBc1bx5UvPmVgBq3lyaMkUKCrK7KgAAAODmEIKQop9+klq0kOLipAcflCZPJgABAAAgayAEwc2sWVbwuXhRevhhadIkKVs2u6sCAAAA0gchCC5mzrSCT3y81Lq19P33UmCg3VUBAAAA6YcQBKdp06RWrawA9Nhj0oQJBCAAAABkPYQgSLI+8/PII1JCgtS2rTRunBQQYHdVAAAAQPojBEGTJklt2kiJidITT0hjxxKAAAAAkHURgnzchAnWzE9iovTUU9Lo0ZK/v91VAQAAAJ5DCPJh331nzfwkJUlPPy19/TUBCAAAAFkfIchHffut9OSTVgB65hlp5EjJj7MBAAAAPoC3vT7om2+kDh0kY6Rnn5W++IIABAAAAN/BW18fM2qU1LGjFYCee0767DMCEAAAAHwLb399yJdfWkvfJOn556VPP5UcDntrAgAAADIaIchHfPaZtfRNkl58URo2jAAEAAAA30QI8gGffip17Wp9/fLL0kcfEYAAAADguwhBWdywYdbSN0l67TXpgw8IQAAAAPBthKAs7KOPrKVvktSzpzR4MAEIAAAAIARlUR98YC19k6S335YGDCAAAQAAABIhKEsaPNha+iZJffpI/fsTgAAAAIBkhKAsZsAAa+mbJPXrJ/XubW89AAAAgLchBGUh/fpZS98kKwy984699QAAAADeKMDuAnDzjJH69rV+SdZyuNdft7cmAAAAwFsRgjI5Y6RevaR337Vuf/CB9Mor9tYEAAAAeDNCUCZmjPTWW9KgQdbtjz6SXnrJ3poAAAAAb0cIyqSMkd54Q3r/fev20KHSCy/YWhIAAACQKRCCMiFjpFdflYYMsW4PHy5162ZvTQAAAEBmQQjKZIyRevSwZn4k6bPPpP/9z9aSAAAAgEyFEJSJGCO9+KL0ySfW7S+/lDp3trUkAAAAINMhBGUSxkjPPy+NGCE5HNJXX0mdOtldFQAAAJD5EIIygaQkqWtX6YsvrAD09ddShw52VwUAAABkToQgL5eUJD37rDRypBWARo+W2re3uyoAAAAg8yIEebGkJOmZZ6RvvpH8/KRvv5XatbO7KgAAACBzIwR5qcREqWNHK/j4+Unjxklt29pdFQAAAJD5EYK8UGKi9ZmfceMkf39p/Hjp0UftrgoAAADIGghBXiYhwfrMz4QJVgD6/nupdWu7qwIAAACyDkKQF0lIkJ54Qpo4UQoIkCZNkh56yO6qAAAAgKyFEOQl4uOlxx+XJk+WAgOlH36QWra0uyoAAAAg6yEEeYH4eKlNG2nqVCsATZ0qNWtmd1UAAABA1kQIstnFi9amBzNmSNmySdOmSfffb3dVAAAAQNZFCLJRXJz0yCPSjz9KQUHS9OlSkyZ2VwUAAABkbYQgm8TFSQ8/LP30kxQcbM0ENWpkd1UAAABA1kcIssGFC9aub3PnWgFo1iypQQO7qwIAAAB8AyEog50/Lz34oDR/vpQ9uzR7tnTffXZXBQAAAPgOQlAGOnfO2vZ64UIpJMRaCle3rt1VAQAAAL6FEJRBzp2ztr1eskQKDZXmzJFq17a7KgAAAMD3EIIyQGys9MAD0rJlUo4c0rx50t13210VAAAA4JsIQR529qx13Z8VK6ScOa0AVKuW3VUBAAAAvosQ5EFnzkhNm0o//yyFhVmbIdx1l91VAQAAAL6NEOQhMTHWhU9//VUKD5cWLJCqV7e7KgAAAACEoHSQmCgtX+7QihWFFRrq0J13WkvgVq+WcuWydoOrWtXuKgEAAABIhKCbNm2a9MIL0r59AZKq6qOPpGzZpIsXpdy5pUWLpDvvtLtKAAAAAMkIQTdh2jSpVSvJGNfjFy9av7/1FgEIAAAA8DZ+dhcgSSNGjFDx4sUVHBysGjVq6Pfff7e7pOtKTLRmgK4MQMkcDmnYMGscAAAAAO9hewiaNGmSevTood69e+uPP/7QHXfcoUaNGunIkSN2l3ZNK1dK+/Zd/X5jpL17rXEAAAAAvIftIeijjz7SM888ow4dOqh8+fL64osvFBISom+++cbu0q7p4MH0HQcAAAAgY9j6maCLFy9q3bp16tmzp/OYn5+fGjRooFWrVrmNj4uLU1xcnPN2TEyMJCk+Pl7x8fGeL/gykZEOpaZ9kZEJio+/ypo5pFryn29G/zn7EnrsWfTXs+ivZ9Ffz6K/nkV/Pcub+puWGhzGXO1TLZ534MABFS5cWL/++qtq1qzpPP7aa69p+fLl+u2331zG9+nTR3379nV7nAkTJigkJMTj9V4uMVHq3Lmhjh8PluRIYYRRRMR5ffnlQvn7Z2hpAAAAgM85d+6c2rZtq9OnTyssLOyaYzPV7nA9e/ZUjx49nLdjYmJUtGhRNWzY8Lov1BM++8yhxx6TJCNjLgUhh8PKlSNGZFOzZk0zvK6sKD4+XgsXLlR0dLQCAwPtLidLoseeRX89i/56Fv31LPrrWfTXs7ypv8mrxFLD1hAUEREhf39/HT582OX44cOHVaBAAbfxQUFBCgoKcjseGBhoS9MfeUQKCEi+TtCl40WKODR0qPTQQ5kqY2YKdv1Z+xJ67Fn017Por2fRX8+iv55Ffz3LG/qblue3dWOEbNmyKSoqSosXL3YeS0pK0uLFi12Wx3mzhx6Sdu2SFi5MUI8ea7VwYYJ27rSOAwAAAPA+tk9V9OjRQ+3bt1fVqlVVvXp1DR06VLGxserQoYPdpaWav79Up45RbOx+1alzB58BAgAAALyY7SHo0Ucf1dGjR9WrVy8dOnRIlStX1rx585Q/f367SwMAAACQBdkegiSpW7du6tatm91lAAAAAPABtl8sFQAAAAAyEiEIAAAAgE8hBAEAAADwKYQgAAAAAD6FEAQAAADApxCCAAAAAPgUQhAAAAAAn0IIAgAAAOBTCEEAAAAAfAohCAAAAIBPIQQBAAAA8CkBdhdwM4wxkqSYmBibK5Hi4+N17tw5xcTEKDAw0O5yshz663n02LPor2fRX8+iv55Ffz2L/nqWN/U3ORMkZ4RrydQh6MyZM5KkokWL2lwJAAAAAG9w5swZhYeHX3OMw6QmKnmppKQkHThwQDlz5pTD4bC1lpiYGBUtWlR79+5VWFiYrbVkRfTX8+ixZ9Ffz6K/nkV/PYv+ehb99Sxv6q8xRmfOnFGhQoXk53ftT/1k6pkgPz8/FSlSxO4yXISFhdl+AmRl9Nfz6LFn0V/Por+eRX89i/56Fv31LG/p7/VmgJKxMQIAAAAAn0IIAgAAAOBTCEHpJCgoSL1791ZQUJDdpWRJ9Nfz6LFn0V/Por+eRX89i/56Fv31rMza30y9MQIAAAAApBUzQQAAAAB8CiEIAAAAgE8hBAEAAADwKYQgAAAAAD4ly4egQYMGqVq1asqZM6fy5cunli1basuWLS5jLly4oK5duypv3rzKkSOHHn74YR0+fNhlTPfu3RUVFaWgoCBVrlw5xecyxujDDz9UmTJlFBQUpMKFC2vAgAHXrO/EiRN6/PHHFRYWply5cqljx446e/asy5i//vpL9957r4KDg1W0aFG9//77aW+Eh3hzf3ft2qWOHTuqRIkSyp49u0qWLKnevXvr4sWLLmMcDofbr9WrV994U9KRN/dXkooXL+7Wu8GDB7uM4fy1pLW/y5YtS/HcdDgcWrNmjSTO32R9+vRJsQ+hoaHXrG/Pnj26//77FRISonz58unVV19VQkKCy5hly5bpzjvvVFBQkEqVKqUxY8bcUC88wZv7++eff6pNmzYqWrSosmfPrnLlymnYsGEuY652jh86dOjGm5KOvLm/klL8nokTJ7qM4fy9sf6OGTPmqv/+HjlyRBLn7+Xmz5+vu+66Szlz5lRkZKQefvhh7dq165r1ecX7X5PFNWrUyIwePdr8/fffZsOGDaZp06bmlltuMWfPnnWOefbZZ03RokXN4sWLzdq1a81dd91latWq5fI4zz//vPn000/NE088Ye64444Un+v55583ZcuWNTNnzjQ7duwwa9euNQsWLLhmfY0bNzZ33HGHWb16tVm5cqUpVaqUadOmjfP+06dPm/z585vHH3/c/P333+b777832bNnN19++eWNNyUdeXN/586da5566ikzf/58s337djNz5kyTL18+8/LLLzvH7Ny500gyixYtMgcPHnT+unjx4s01Jp14c3+NMaZYsWKmX79+Lr27vDbOX9cxaelvXFycS18PHjxoOnXqZEqUKGGSkpKMMZy/yc6cOePWq/Lly5v27dtftbaEhARTsWJF06BBA7N+/XozZ84cExERYXr27Okcs2PHDhMSEmJ69OhhNm3aZIYPH278/f3NvHnzbro36cGb+/v111+b7t27m2XLlpnt27ebcePGmezZs5vhw4c7xyxdutRIMlu2bHF57MTExJvuTXrw5v4aY4wkM3r0aJfvO3/+vPN+zl/LjfT33Llzbt/TqFEjU6dOHecYzl/Ljh07TFBQkOnZs6fZtm2bWbdunaldu7apUqXKNevzhve/WT4EXenIkSNGklm+fLkxxphTp06ZwMBAM3nyZOeYzZs3G0lm1apVbt/fu3fvFE+CTZs2mYCAAPPvv/+mupZNmzYZSWbNmjXOY3PnzjUOh8Ps37/fGGPMZ599ZnLnzm3i4uKcY15//XVTtmzZVD9PRvKm/qbk/fffNyVKlHDeTn4TuX79+pt63Izibf0tVqyY+fjjj696P+evJT3O34sXL5rIyEjTr18/5zHO35Rt2LDBSDIrVqy46pg5c+YYPz8/c+jQIeexzz//3ISFhTnP19dee81UqFDB5fseffRR06hRo+vWYAdv6m9KnnvuOVOvXj3n7eQ3kSdPnkzT49jF2/oryUyfPv2q93P+puxGzt8jR46YwMBAM3bsWOcxzl/L5MmTTUBAgEv4+/HHH43D4bjqD+S85f1vll8Od6XTp09LkvLkySNJWrduneLj49WgQQPnmNtuu0233HKLVq1alerHnTVrlm699VbNnj1bJUqUUPHixdWpUyedOHHiqt+zatUq5cqVS1WrVnUea9Cggfz8/PTbb785x9SuXVvZsmVzjmnUqJG2bNmikydPprq+jOJN/b1afcm1Xa558+bKly+f7rnnHv34449pesyM5I39HTx4sPLmzasqVarogw8+cFlOxPlrSY/z98cff9Tx48fVoUMHt/t8/fy90qhRo1SmTBnde++9Vx2zatUq3X777cqfP7/zWKNGjRQTE6N//vnHOeby2pLH3ExtnuRN/b1afSn9+1u5cmUVLFhQ0dHR+uWXX264Lk/zxv527dpVERERql69ur755huZyy79yPmbshs5f8eOHauQkBC1atXK7T5fP3+joqLk5+en0aNHKzExUadPn9a4cePUoEEDBQYGpvg93vL+16dCUFJSkl588UXdfffdqlixoiTp0KFDypYtm3LlyuUyNn/+/Gla17ljxw7t3r1bkydP1tixYzVmzBitW7cuxb8wyQ4dOqR8+fK5HAsICFCePHmcz33o0CGX/6STa0u+z5t4W3+vtG3bNg0fPlxdunRxHsuRI4eGDBmiyZMn66efftI999yjli1beuUbSW/sb/fu3TVx4kQtXbpUXbp00cCBA/Xaa6857+f8taTH+fv111+rUaNGKlKkiPMY56+7CxcuaPz48erYseM1x6Xm3LzamJiYGJ0/f/6G6vMUb+vvlX799VdNmjRJnTt3dh4rWLCgvvjiC02dOlVTp05V0aJFVbduXf3xxx83VJsneWN/+/Xrpx9++EELFy7Uww8/rOeee07Dhw933s/56+5Gz9+vv/5abdu2Vfbs2Z3HOH8tJUqU0IIFC/Tmm28qKChIuXLl0r59+/TDDz9c9Xu85f1vQLo8SibRtWtX/f333/r555/T/bGTkpIUFxensWPHqkyZMpKsvzRRUVHasmWLypYtm+7P6W28ub/79+9X48aN1bp1az3zzDPO4xEREerRo4fzdrVq1XTgwAF98MEHat68ebq/jpvhjf29vHeVKlVStmzZ1KVLFw0aNEhBQUHpXqcneWN/k+3bt0/z5893+0+F89fd9OnTdebMGbVv396jz+NtvLm/f//9t1q0aKHevXurYcOGzuNly5Z1Ofdr1aql7du36+OPP9a4cePSte6b5Y39feedd5xfV6lSRbGxsfrggw/UvXt3T5boEd7Y32SrVq3S5s2b3c5Jzl/LoUOH9Mwzz6h9+/Zq06aNzpw5o169eqlVq1ZauHChHA5Huj9nevGZmaBu3bpp9uzZWrp0qctPUgsUKKCLFy/q1KlTLuMPHz6sAgUKpPrxCxYsqICAAOcbHEkqV66cJGsHopQUKFDAuctIsoSEBJ04ccL53AUKFHDbqSP5dlrq8zRv7G+yAwcOqF69eqpVq5a++uqr6z5XjRo1tG3btlTXlhG8ub+Xq1GjhhISEpy7wnD+Wm62v6NHj1bevHlTFWx88fy93KhRo/TAAw+4/QTxSqk5N682JiwszOUnwnbzxv4m27Rpk+rXr6/OnTvr7bffvu746tWrc/6mob+Xq1Gjhvbt26e4uDhnfZy/rm6kv6NGjVLlypUVFRV13bG+eP6OGDFC4eHhev/991WlShXVrl1b3333nRYvXuxc2nYlb3n/m+VDkDFG3bp10/Tp07VkyRKVKFHC5f6oqCgFBgZq8eLFzmNbtmzRnj17VLNmzVQ/z913362EhARt377deey///6TJBUrVizF76lZs6ZOnTqldevWOY8tWbJESUlJqlGjhnPMihUrFB8f7xyzcOFClS1bVrlz5051fZ7izf2VrBmgunXrKioqSqNHj5af3/VP+Q0bNqhgwYKprs2TvL2/V9qwYYP8/Pyc09ycv5ab6a8xRqNHj9aTTz551fXVl/PF8zfZzp07tXTp0lQtdalZs6Y2btzo8h/xwoULFRYWpvLlyzvHXF5b8pgbqc0TvLm/kvTPP/+oXr16at++/XW320/G+Zv6/l5pw4YNyp07t3MWnvPX1Y309+zZs/rhhx9S/T2+eP6eO3fO7b2Vv7+/JGsVREq85v1vum2x4KX+97//mfDwcLNs2TKXLQzPnTvnHPPss8+aW265xSxZssSsXbvW1KxZ09SsWdPlcbZu3WrWr19vunTpYsqUKWPWr19v1q9f79y1IjEx0dx5552mdu3a5o8//jBr1641NWrUMNHR0c7H+O2330zZsmXNvn37nMcaN25sqlSpYn777Tfz888/m9KlS7tsEXjq1CmTP39+88QTT5i///7bTJw40YSEhHjNFsPe3N99+/aZUqVKmfr165t9+/a51JdszJgxZsKECWbz5s1m8+bNZsCAAcbPz8988803nmxbqnlzf3/99Vfz8ccfmw0bNpjt27eb7777zkRGRponn3zS+T2cvzf374MxxixatMhIMps3b3arn/M3zmXc22+/bQoVKmQSEhLcapk2bZrLrkLJW2Q3bNjQbNiwwcybN89ERkamuEX2q6++ajZv3mxGjBjhVVsMe3N/N27caCIjI027du1cajty5IhzzMcff2xmzJhhtm7dajZu3GheeOEF4+fnZxYtWpReLbop3tzfH3/80YwcOdJs3LjRbN261Xz22WcmJCTE9OrVyzmG8/fG+5ts1KhRJjg4OMUd4Dh/rf4uXrzYOBwO07dvX/Pff/+ZdevWmUaNGplixYo5n8tb3/9m+RAkKcVfo0ePdo45f/68ee6550zu3LlNSEiIefDBB13eKBtjTJ06dVJ8nJ07dzrH7N+/3zz00EMmR44cJn/+/Oapp54yx48fd96fvJ3i5d9z/Phx06ZNG5MjRw4TFhZmOnToYM6cOePy3H/++ae55557TFBQkClcuLAZPHhwuvboZnhzf0ePHn3V+pKNGTPGlCtXzoSEhJiwsDBTvXp1l+0i7ebN/V23bp2pUaOGCQ8PN8HBwaZcuXJm4MCB5sKFCy7PzflruZF/H4wxpk2bNm7XbUjG+bvTOSYxMdEUKVLEvPnmmynWkvzvweV27dplmjRpYrJnz24iIiLMyy+/bOLj413GLF261FSuXNlky5bN3HrrrS61282b+9u7d+8UH7NYsWLOMe+9954pWbKkCQ4ONnny5DF169Y1S5YsSZfepAdv7u/cuXNN5cqVTY4cOUxoaKi54447zBdffOF2jRrOX8uN/PtgjDE1a9Y0bdu2TfF7OH93Osd8//33pkqVKiY0NNRERkaa5s2bu/zgzlvf/zqMuWw/RQAAAADI4rL8Z4IAAAAA4HKEIAAAAAA+hRAEAAAAwKcQggAAAAD4FEIQAAAAAJ9CCAIAAADgUwhBAAAAAHwKIQgAAACATyEEAQAAAPAphCAAgNcwxqhBgwZq1KiR232fffaZcuXKpX379tlQGQAgKyEEAQC8hsPh0OjRo/Xbb7/pyy+/dB7fuXOnXnvtNQ0fPlxFihRJ1+eMj49P18cDAHg/QhAAwKsULVpUw4YN0yuvvKKdO3fKGKOOHTuqYcOGqlKlipo0aaIcOXIof/78euKJJ3Ts2DHn986bN0/33HOPcuXKpbx58+qBBx7Q9u3bnffv2rVLDodDkyZNUp06dRQcHKzx48fb8TIBADZyGGOM3UUAAHClli1b6vTp03rooYfUv39//fPPP6pQoYI6deqkJ598UufPn9frr7+uhIQELVmyRJI0depUORwOVapUSWfPnlWvXr20a9cubdiwQX5+ftq1a5dKlCih4sWLa8iQIapSpYqCg4NVsGBBm18tACAjEYIAAF7pyJEjqlChgk6cOKGpU6fq77//1sqVKzV//nznmH379qlo0aLasmWLypQp4/YYx44dU2RkpDZu3KiKFSs6Q9DQoUP1wgsvZOTLAQB4EZbDAQC8Ur58+dSlSxeVK1dOLVu21J9//qmlS5cqR44czl+33XabJDmXvG3dulVt2rTRrbfeqrCwMBUvXlyStGfPHpfHrlq1aoa+FgCAdwmwuwAAAK4mICBAAQHWf1Vnz55Vs2bN9N5777mNS17O1qxZMxUrVkwjR45UoUKFlJSUpIoVK+rixYsu40NDQz1fPADAaxGCAACZwp133qmpU6eqePHizmB0uePHj2vLli0aOXKk7r33XknSzz//nNFlAgAyAZbDAQAyha5du+rEiRNq06aN1qxZo+3bt2v+/Pnq0KGDEhMTlTt3buXNm1dfffWVtm3bpiVLlqhHjx52lw0A8EKEIABAplCoUCH98ssvSkxMVMOGDXX77bfrxRdfVK5cueTn5yc/Pz9NnDhR69atU8WKFfXSSy/pgw8+sLtsAIAXYnc4AAAAAD6FmSAAAAAAPoUQBAAAAMCnEIIAAAAA+BRCEAAAAACfQggCAAAA4FMIQQAAAAB8CiEIAAAAgE8hBAEAAADwKYQgAAAAAD6FEAQAAADApxCCAAAAAPiU/wOwcFEAg4GevQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Time for executing function: 2.4710421562194824 seconds\n",
      "INFO:root:Total execution time: 21.453243255615234 seconds\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Plot the total number of orders by year.\"\n",
    "\n",
    "# Copy original data frames\n",
    "df, customer_df, product_df = data_copy(orig_df, orig_customer_df, orig_product_df)\n",
    "\n",
    "get_response(user_query, mode=\"FULL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python new (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
